# -*- coding: utf-8 -*-
"""Assignment_fire.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1toNZEdYExSAYQSR0rdWzbaQoz5h2wrig
"""

import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import os
import random
import scipy
import seaborn as sns
import math
from scipy import stats
import tensorflow as tf

import sys
print(sys.version)
print(tf.__version__)
pd.show_versions()

"""### **Data Processing**"""

from google.colab import files
uploaded = files.upload()

df = pd.read_csv('Fire_data.csv')
df2=df.copy()
df2.head(10)

!pip install geopy 
import geopy.distance

def dist(x,y):
  coords_1 = (45.504654, -73.56546)
  coords_2 = (x, y)
  return geopy.distance.distance(coords_1, coords_2).km

df2['distance']=0

for i in range(0,len(df2)-1):
  df2['distance'][i]=dist(df2['latitude'][i], df2['longitude'][i])

df2['fire'] = df2['incendie_count']
df2['fire'][df2['incendie_count']==0] = 0
df2['fire'][(df2['incendie_count']==1)] = 1
df2['fire'][df2['incendie_count']>=2] = 2

df2 = df2.drop("latitude", axis=1)
df2 = df2.drop("longitude", axis=1)      
df2 = df2.drop("incendie_count", axis=1)
df3 = df2.drop("year",axis=1)
df3 = df3.drop("quarter",axis=1)
df2['fire'].value_counts()

corr_matrix = df2.corr()
X_raw=df3.drop("fire", axis=1)
corr_matrix["fire"].sort_values(ascending=False)

from sklearn import preprocessing

# standardize X and y before fitting multiple linear model
X = pd.DataFrame(preprocessing.scale(X_raw))
y = df3['fire'].copy()

X_train = X[df2['year'] < 2019]
y_train = y[df2['year'] < 2019]

X_test = X[(df2['year']==2019) & (df2['quarter']==1)]
y_test = y[(df2['year']==2019) & (df2['quarter']==1)]
len(X_train),len(y_train),len(X_test),len(y_test)

"""### **Decision Tree**"""

from sklearn.tree import DecisionTreeClassifier

tree_clf = DecisionTreeClassifier()
tree_clf.fit(X_train, y_train)

from sklearn.metrics import accuracy_score
from sklearn.metrics import confusion_matrix

y_test_pred = tree_clf.predict(X_test)
confusion_matrix_valid = confusion_matrix(y_test, y_test_pred)
print(confusion_matrix_valid) 
y_train_pred = tree_clf.predict(X_train)
print(f'Train score {accuracy_score(y_train_pred,y_train)}')
print(f'Test score {accuracy_score(y_test_pred,y_test)}')

from sklearn.model_selection import GridSearchCV 



param_test1 = {
  'max_depth':(2,6,10,100,200,500,1000),
  'max_features':(2,5,10,15,20,100),
}
gsearch1 = GridSearchCV(estimator = DecisionTreeClassifier(), param_grid = param_test1,scoring='accuracy', n_jobs=4, cv=5)
gsearch1.fit(X_train, y_train)
gsearch1.cv_results_

from sklearn.tree import DecisionTreeClassifier

tree_clf = DecisionTreeClassifier(max_depth=6,max_features=10)
tree_clf.fit(X_train, y_train)
y_test_pred = tree_clf.predict(X_test)

from sklearn.metrics import accuracy_score
from sklearn.metrics import confusion_matrix

y_test_pred = tree_clf.predict(X_test)
confusion_matrix_valid = confusion_matrix(y_test, y_test_pred)
print(confusion_matrix_valid) 
y_train_pred = tree_clf.predict(X_train)
print(f'Train score {accuracy_score(y_train_pred,y_train)}')
print(f'Test score {accuracy_score(y_test_pred,y_test)}')

path = tree_clf.cost_complexity_pruning_path(X_train, y_train)
ccp_alphas, impurities = path.ccp_alphas, path.impurities
print(ccp_alphas)

# For each alpha we will append our model to a list
clfs = []
for ccp_alpha in ccp_alphas:
    clf = DecisionTreeClassifier(random_state=0, ccp_alpha=ccp_alpha)
    clf.fit(X_train, y_train)
    clfs.append(clf)

clfs = clfs[:-1]
ccp_alphas = ccp_alphas[:-1]
node_counts = [clf.tree_.node_count for clf in clfs]
depth = [clf.tree_.max_depth for clf in clfs]
plt.scatter(ccp_alphas,node_counts)
plt.scatter(ccp_alphas,depth)
plt.plot(ccp_alphas,node_counts,label='no of nodes',drawstyle="steps-post")
plt.plot(ccp_alphas,depth,label='depth',drawstyle="steps-post")
plt.legend()
plt.show()

from sklearn.metrics import accuracy_score
from sklearn.metrics import confusion_matrix


train_acc = []
test_acc = []
for c in clfs:
    y_train_pred = c.predict(X_train)
    y_test_pred = c.predict(X_test)
    train_acc.append(accuracy_score(y_train_pred,y_train))
    test_acc.append(accuracy_score(y_test_pred,y_test))

plt.scatter(ccp_alphas,train_acc)
plt.scatter(ccp_alphas,test_acc)
plt.plot(ccp_alphas,train_acc,label='train_accuracy',drawstyle="steps-post")
plt.plot(ccp_alphas,test_acc,label='test_accuracy',drawstyle="steps-post")
plt.legend()
plt.title('Accuracy vs alpha')
plt.show()

from sklearn.metrics import accuracy_score
from sklearn.metrics import confusion_matrix

clf_ = DecisionTreeClassifier(random_state=0,ccp_alpha=0.0025)
clf_.fit(X_train,y_train)
y_train_pred = clf_.predict(X_train)
y_test_pred = clf_.predict(X_test)

print(f'Train score {accuracy_score(y_train_pred,y_train)}')
print(f'Test score {accuracy_score(y_test_pred,y_test)}')

from sklearn.metrics import accuracy_score
from sklearn.metrics import confusion_matrix

y_test_pred = clf_.predict(X_test)
confusion_matrix_valid = confusion_matrix(y_test, y_test_pred)
accuracy_score = accuracy_score(y_test, y_test_pred)
print(confusion_matrix_valid, accuracy_score)

"""https://www.kaggle.com/arunmohan003/pruning-decision-trees-tutorial

### **Neural Network**
"""

from tensorflow import keras
from tensorflow.keras.layers import BatchNormalization
model = keras.models.Sequential([   
    keras.layers.Dense(300, activation="relu"),
    keras.layers.Dense(100, activation="relu"),
    keras.layers.Dense(3, activation="sigmoid")
])

model.compile(loss="sparse_categorical_crossentropy",
              optimizer="sgd",
              metrics=["accuracy"])
history = model.fit(X_train, y_train, epochs=30)
model.evaluate(X_test, y_test)

from tensorflow.keras.optimizers import SGD, Adam, Adagrad, RMSprop
import tensorflow.keras.backend as K

dflist = []

optimizers = ['SGD(learning_rate=0.01)',
              'SGD(learning_rate=0.01, momentum=0.3)',
              'SGD(learning_rate=0.01, momentum=0.3, nesterov=True)',  
              'Adam(learning_rate=0.01)',
              'Adagrad(learning_rate=0.01)',
              'RMSprop(learning_rate=0.01)']

for opt_name in optimizers:

    K.clear_session()    
    model = keras.models.Sequential([   
    keras.layers.Dense(300, activation="relu"),
    keras.layers.Dense(100, activation="relu"),
    keras.layers.Dense(3, activation="sigmoid")])    
    model.compile(loss='sparse_categorical_crossentropy',
                  optimizer=eval(opt_name),
                  metrics=['accuracy'])
    h = model.fit(X_train, y_train, batch_size=16, epochs=5, verbose=0)    
    print(opt_name)
    print(model.evaluate(X_test, y_test))

from tensorflow.keras.optimizers import SGD, Adam, Adagrad, RMSprop
import tensorflow.keras.backend as K

dflist = []

batch_sizes = [16, 32, 64, 128,1000]

for batch_size in batch_sizes:
    K.clear_session()    
    model = keras.models.Sequential([   
    keras.layers.Dense(300, activation="relu"),
    keras.layers.Dense(100, activation="relu"),
    keras.layers.Dense(3, activation="sigmoid")])    

    model.compile(loss='sparse_categorical_crossentropy',
                  optimizer='sgd',
                  metrics=['accuracy'])
    h = model.fit(X_train, y_train, batch_size=batch_size, verbose=0, epochs=10)
    print(batch_size)
    print(model.evaluate(X_test, y_test))

from tensorflow import keras
from tensorflow.keras.layers import BatchNormalization
model = keras.models.Sequential([   
    keras.layers.Dense(300, activation="relu"),
    keras.layers.Dense(100, activation="relu"),
    keras.layers.Dense(3, activation="softmax")
])
model.add(BatchNormalization())
model.compile(loss="sparse_categorical_crossentropy",
              optimizer="sgd",
              metrics=["accuracy"])
history = model.fit(X_train, y_train, epochs=10)
model.evaluate(X_test, y_test)

dflist = []

learning_rates = [.001,0.01, 0.05, 0.1, 0.5,1]

for learning_rate in learning_rates:
    K.clear_session()    
    model = keras.models.Sequential([   
    keras.layers.Dense(300, activation="relu"),
    keras.layers.Dense(100, activation="relu"),
    keras.layers.Dense(3, activation="sigmoid")])    

    model.compile(loss='sparse_categorical_crossentropy',
                  optimizer=SGD(learning_rate=learning_rate),
                  metrics=['accuracy'])
    h = model.fit(X_train, y_train, batch_size=128, verbose=0, epochs=10)
    print(learning_rate)
    print(model.evaluate(X_test, y_test))

dflist = []

initializers = ['zeros', 
                'uniform', 
                'normal',
                'he_normal', 
                'lecun_uniform']

for initializers in initializers:
    K.clear_session()    
    model = keras.models.Sequential([   
    keras.layers.Dense(300, activation="relu",kernel_initializer=initializers),
    keras.layers.Dense(100, activation="relu"),
    keras.layers.Dense(3, activation="sigmoid")])    

    model.compile(loss='sparse_categorical_crossentropy',
                  optimizer=SGD(learning_rate=learning_rate),
                  metrics=['accuracy'])
    h = model.fit(X_train, y_train, batch_size=128, verbose=0, epochs=10)
    print(initializers)
    print(model.evaluate(X_test, y_test))

from sklearn.metrics import accuracy_score
from sklearn.metrics import confusion_matrix

y_test_pred = model.predict(X_test)
#confusion_matrix_valid = confusion_matrix(y_test, y_test_pred)
#accuracy_score = accuracy_score(y_test, y_test_pred)
#print(confusion_matrix_valid, accuracy_score)

"""### **ADAboost**"""

from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import AdaBoostClassifier

ada_clf = AdaBoostClassifier(
    DecisionTreeClassifier(max_depth=1), n_estimators=200,
    algorithm="SAMME.R", learning_rate=0.5, random_state=42)
ada_clf.fit(X_train, y_train)

from sklearn.metrics import confusion_matrix
from sklearn.metrics import accuracy_score

y_train_pred = ada_clf.predict(X_train)
y_test_pred = ada_clf.predict(X_test)

print(f'Train score {accuracy_score(y_train_pred,y_train)}')
print(f'Test score {accuracy_score(y_test_pred,y_test)}')

from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import AdaBoostClassifier

ada_clf = AdaBoostClassifier(
    DecisionTreeClassifier(max_depth=1), n_estimators=50,
    algorithm="SAMME.R", learning_rate=1, random_state=42)
ada_clf.fit(X_train, y_train)
y_train_pred = ada_clf.predict(X_train)
y_test_pred = ada_clf.predict(X_test)

print(f'Train score {accuracy_score(y_train_pred,y_train)}')
print(f'Test score {accuracy_score(y_test_pred,y_test)}')

from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import AdaBoostClassifier

ada_clf = AdaBoostClassifier(
    DecisionTreeClassifier(max_depth=1), n_estimators=100,
    algorithm="SAMME.R", learning_rate=5, random_state=42)
ada_clf.fit(X_train, y_train)
y_train_pred = ada_clf.predict(X_train)
y_test_pred = ada_clf.predict(X_test)

print(f'Train score {accuracy_score(y_train_pred,y_train)}')
print(f'Test score {accuracy_score(y_test_pred,y_test)}')

from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import AdaBoostClassifier

ada_clf = AdaBoostClassifier(
    DecisionTreeClassifier(max_depth=1), n_estimators=50,
    algorithm="SAMME.R", learning_rate=.01, random_state=42)
ada_clf.fit(X_train, y_train)
y_train_pred = ada_clf.predict(X_train)
y_test_pred = ada_clf.predict(X_test)

print(f'Train score {accuracy_score(y_train_pred,y_train)}')
print(f'Test score {accuracy_score(y_test_pred,y_test)}')

from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import AdaBoostClassifier

ada_clf = AdaBoostClassifier(
    DecisionTreeClassifier(max_depth=1), n_estimators=100,
    algorithm="SAMME.R", learning_rate=1, random_state=42)
ada_clf.fit(X_train, y_train)
y_train_pred = ada_clf.predict(X_train)
y_test_pred = ada_clf.predict(X_test)

print(f'Train score {accuracy_score(y_train_pred,y_train)}')
print(f'Test score {accuracy_score(y_test_pred,y_test)}')

"""### **SVM**"""

from sklearn.model_selection import GridSearchCV 
from sklearn.svm import SVC


param_test1 = {
  'gamma':(0.01,0.05,0.1),
   'C':(.001,.01,.1,1,1000) 
}
gsearch1 = GridSearchCV(estimator = SVC(class_weight='balanced'), 
param_grid = param_test1,scoring='accuracy', n_jobs=10,iid=False, cv=5)
gsearch1.fit(X_train,y_train)
gsearch1.cv_results_

from sklearn.svm import SVC

final = SVC(C=0.01, break_ties=False, cache_size=200, class_weight='balanced',
    coef0=0.0, decision_function_shape='ovr', degree=3, gamma=0.01,
    kernel='rbf', max_iter=-1, probability=True, random_state=None,
    shrinking=True, tol=0.001, verbose=False)
final.fit(X_train, y_train)
y_train_pred= final.predict(X_train)
y_test_pred = final.predict(X_test)
from sklearn.metrics import confusion_matrix
from sklearn.metrics import accuracy_score

confusion_matrix_valid = confusion_matrix(y_test, y_test_pred)
print(confusion_matrix_valid) 
print(f'Train score {accuracy_score(y_train_pred,y_train)}')
print(f'Test score {accuracy_score(y_test_pred,y_test)}')

from sklearn.svm import SVC

final = SVC(C=0.001, break_ties=False, cache_size=200, class_weight='balanced',
    coef0=0.0, decision_function_shape='ovr', degree=3, gamma=0.01,
    kernel='rbf', max_iter=-1, probability=True, random_state=None,
    shrinking=True, tol=0.001, verbose=False)
final.fit(X_train, y_train)
y_train_pred= final.predict(X_train)
y_test_pred = final.predict(X_test)
from sklearn.metrics import confusion_matrix
from sklearn.metrics import accuracy_score

confusion_matrix_valid = confusion_matrix(y_test, y_test_pred)
print(confusion_matrix_valid) 
print(f'Train score {accuracy_score(y_train_pred,y_train)}')
print(f'Test score {accuracy_score(y_test_pred,y_test)}')

from sklearn.svm import SVC

final = SVC(C=0.001, break_ties=False, cache_size=200, class_weight='balanced',
    coef0=0.0, decision_function_shape='ovr', degree=3, gamma=0.1,
    kernel='rbf', max_iter=-1, probability=True, random_state=None,
    shrinking=True, tol=0.001, verbose=False)
final.fit(X_train, y_train)
y_train_pred= final.predict(X_train)
y_test_pred = final.predict(X_test)
from sklearn.metrics import confusion_matrix
from sklearn.metrics import accuracy_score

confusion_matrix_valid = confusion_matrix(y_test, y_test_pred)
print(confusion_matrix_valid) 
print(f'Train score {accuracy_score(y_train_pred,y_train)}')
print(f'Test score {accuracy_score(y_test_pred,y_test)}')

from sklearn.svm import SVC

final = SVC(C=0.1, break_ties=False, cache_size=200, class_weight='balanced',
    coef0=0.0, decision_function_shape='ovr', degree=3, gamma=0.01,
    kernel='rbf', max_iter=-1, probability=True, random_state=None,
    shrinking=True, tol=0.001, verbose=False)
final.fit(X_train, y_train)
y_train_pred= final.predict(X_train)
y_test_pred = final.predict(X_test)
from sklearn.metrics import confusion_matrix
from sklearn.metrics import accuracy_score

confusion_matrix_valid = confusion_matrix(y_test, y_test_pred)
print(confusion_matrix_valid) 
print(f'Train score {accuracy_score(y_train_pred,y_train)}')
print(f'Test score {accuracy_score(y_test_pred,y_test)}')

from sklearn.svm import SVC

final = SVC(C=0.1, break_ties=False, cache_size=200, class_weight='balanced',
    coef0=0.0, decision_function_shape='ovr', degree=3, gamma=0.1,
    kernel='rbf', max_iter=-1, probability=True, random_state=None,
    shrinking=True, tol=0.001, verbose=False)
final.fit(X_train, y_train)
y_train_pred= final.predict(X_train)
y_test_pred = final.predict(X_test)
from sklearn.metrics import confusion_matrix
from sklearn.metrics import accuracy_score

confusion_matrix_valid = confusion_matrix(y_test, y_test_pred)
print(confusion_matrix_valid) 
print(f'Train score {accuracy_score(y_train_pred,y_train)}')
print(f'Test score {accuracy_score(y_test_pred,y_test)}')

from sklearn.svm import SVC

final = SVC(C=10, break_ties=False, cache_size=200, class_weight='balanced',
    coef0=0.0, decision_function_shape='ovr', degree=3, gamma=0.1,
    kernel='rbf', max_iter=-1, probability=True, random_state=None,
    shrinking=True, tol=0.001, verbose=False)
final.fit(X_train, y_train)
y_train_pred= final.predict(X_train)
y_test_pred = final.predict(X_test)
from sklearn.metrics import confusion_matrix
from sklearn.metrics import accuracy_score

confusion_matrix_valid = confusion_matrix(y_test, y_test_pred)
print(confusion_matrix_valid) 
print(f'Train score {accuracy_score(y_train_pred,y_train)}')
print(f'Test score {accuracy_score(y_test_pred,y_test)}')

"""https://github.com/ageron/handson-ml2"""

## Polynomial Kernel

from sklearn.svm import SVC
from sklearn.pipeline import Pipeline

poly100_kernel_svm_clf = Pipeline([
        ("svm_clf", SVC(kernel="poly", degree=2, coef0=100, C=5,cache_size=200000))
    ])
poly100_kernel_svm_clf.fit(X_train, y_train)

y_train_pred= poly100_kernel_svm_clf.predict(X_train)
y_test_pred = poly100_kernel_svm_clf.predict(X_test)
confusion_matrix_valid = confusion_matrix(y_test, y_test_pred)

accuracy_score = accuracy_score(y_test, y_test_pred)
print(confusion_matrix_valid, accuracy_score) 
from sklearn.metrics import accuracy_score
from sklearn.metrics import confusion_matrix
print(f'Train score {accuracy_score(y_train_pred,y_train)}')
print(f'Test score {accuracy_score(y_test_pred,y_test)}')

"""### **kNN**"""

from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import GridSearchCV 

leaf_size = list(range(1,50,2))
n_neighbors = list(range(180,300,20))

param_test1 = {
  'leaf_size':(1,5,101,5,20,25,30,35,40,45,50,100),
   'n_neighbors':(180,200,230,250,300,400,500) 
}


gsearch1 = GridSearchCV(estimator = KNeighborsClassifier(),param_grid = param_test1,scoring='accuracy', n_jobs=10,iid=False, cv=5)
gsearch1.fit(X_train,y_train)
gsearch1.cv_results_

plt.scatter(gsearch1.cv_results_['mean_test_score'],gsearch1.cv_results_['param_n_neighbors'])
#gsearch1.cv_results_['param_leaf_size'], gsearch1.cv_results_['mean_test_score']

from sklearn.neighbors import KNeighborsClassifier


param_knn = {}
param_knn['n_neighbors'] = 400
param_knn['leaf_size'] = 50

knn = KNeighborsClassifier(**param_knn)
knn.fit(X_train,y_train)

y_test_pred = knn.predict(X_test)
y_train_pred= knn.predict(X_train)

from sklearn.metrics import confusion_matrix
from sklearn.metrics import accuracy_score


print(f'Train score {accuracy_score(y_train_pred,y_train)}')
print(f'Test score {accuracy_score(y_test_pred,y_test)}')

from sklearn.neighbors import KNeighborsClassifier


param_knn = {}
param_knn['n_neighbors'] = 400
param_knn['leaf_size'] = 25

knn = KNeighborsClassifier(**param_knn)
knn.fit(X_train,y_train)

y_test_pred = knn.predict(X_test)
y_train_pred= knn.predict(X_train)

from sklearn.metrics import confusion_matrix
from sklearn.metrics import accuracy_score


print(f'Train score {accuracy_score(y_train_pred,y_train)}')
print(f'Test score {accuracy_score(y_test_pred,y_test)}')

from sklearn.neighbors import KNeighborsClassifier


param_knn = {}
param_knn['n_neighbors'] = 400
param_knn['leaf_size'] = 100

knn = KNeighborsClassifier(**param_knn)
knn.fit(X_train,y_train)

y_test_pred = knn.predict(X_test)
y_train_pred= knn.predict(X_train)

from sklearn.metrics import confusion_matrix
from sklearn.metrics import accuracy_score


print(f'Train score {accuracy_score(y_train_pred,y_train)}')
print(f'Test score {accuracy_score(y_test_pred,y_test)}')

from sklearn.neighbors import KNeighborsClassifier


param_knn = {}
param_knn['n_neighbors'] = 200
param_knn['leaf_size'] = 100

knn = KNeighborsClassifier(**param_knn)
knn.fit(X_train,y_train)

y_test_pred = knn.predict(X_test)
y_train_pred= knn.predict(X_train)

from sklearn.metrics import confusion_matrix
from sklearn.metrics import accuracy_score


print(f'Train score {accuracy_score(y_train_pred,y_train)}')
print(f'Test score {accuracy_score(y_test_pred,y_test)}')

from sklearn.neighbors import KNeighborsClassifier


param_knn = {}
param_knn['n_neighbors'] = 800
param_knn['leaf_size'] = 100

knn = KNeighborsClassifier(**param_knn)
knn.fit(X_train,y_train)

y_test_pred = knn.predict(X_test)
y_train_pred= knn.predict(X_train)

from sklearn.metrics import confusion_matrix
from sklearn.metrics import accuracy_score


print(f'Train score {accuracy_score(y_train_pred,y_train)}')
print(f'Test score {accuracy_score(y_test_pred,y_test)}')