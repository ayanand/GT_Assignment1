# -*- coding: utf-8 -*-
"""Assignment_Imdb.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1usTv1avnk7Y4z1x9cGf3CP1BBiOaTawM
"""

!wget https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz

!tar -xf aclImdb_v1.tar.gz

from glob import glob
pos_train = [(open(x).read(), 1) for x in glob('aclImdb/train/pos/*.txt')]
neg_train = [(open(x).read(), 0) for x in glob('aclImdb/train/neg/*.txt')]
X_train_text, y_train = zip(*(pos_train + neg_train))

pos_test = [(open(x).read(), 1) for x in glob('aclImdb/test/pos/*.txt')]
neg_test = [(open(x).read(), 0) for x in glob('aclImdb/test/neg/*.txt')]
X_test_text, y_test = zip(*(pos_test + neg_test))

import numpy as np
y_train, y_test = np.array(y_train), np.array(y_test)

X_train_text[0], y_train[0]

!wget -c "https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz"
!gunzip GoogleNews-vectors-negative300.bin.gz

from gensim.models import KeyedVectors
filename = 'GoogleNews-vectors-negative300.bin'
w2v = KeyedVectors.load_word2vec_format(filename, binary=True)
from nltk.tokenize import word_tokenize
import nltk
nltk.download('punkt')
# takes a minute
X_train = [[w2v.get_vector(word) for word in word_tokenize(x) if word in w2v.vocab] for x in X_train_text]
X_test = [[w2v.get_vector(word) for word in word_tokenize(x) if word in w2v.vocab] for x in X_test_text]

X_train = np.array([np.array(x).mean(axis=0) for x in X_train])
X_test =  np.array([np.array(x).mean(axis=0) for x in X_test])

"""### **Decision Tree**"""

from sklearn.tree import DecisionTreeClassifier

tree_clf = DecisionTreeClassifier()
tree_clf.fit(X_train, y_train)

from sklearn.metrics import accuracy_score
from sklearn.metrics import confusion_matrix

y_test_pred = tree_clf.predict(X_test)
confusion_matrix_valid = confusion_matrix(y_test, y_test_pred)
print(confusion_matrix_valid) 
y_train_pred = tree_clf.predict(X_train)
print(f'Train score {accuracy_score(y_train_pred,y_train)}')
print(f'Test score {accuracy_score(y_test_pred,y_test)}')

from sklearn.model_selection import GridSearchCV 



param_test1 = {
  'max_depth':(2,10,100,200,500,1000),
  'max_features':(2,5,10,15,20,100),
}
gsearch1 = GridSearchCV(estimator = DecisionTreeClassifier(), param_grid = param_test1,scoring='accuracy', n_jobs=4, cv=5)
gsearch1.fit(X_train, y_train)
gsearch1.cv_results_

from sklearn.tree import DecisionTreeClassifier

tree_clf = DecisionTreeClassifier(max_depth=10,max_features=100)
tree_clf.fit(X_train, y_train)
y_test_pred = tree_clf.predict(X_test)

from sklearn.metrics import accuracy_score
from sklearn.metrics import confusion_matrix

y_test_pred = tree_clf.predict(X_test)
confusion_matrix_valid = confusion_matrix(y_test, y_test_pred)
print(confusion_matrix_valid) 
y_train_pred = tree_clf.predict(X_train)
print(f'Train score {accuracy_score(y_train_pred,y_train)}')
print(f'Test score {accuracy_score(y_test_pred,y_test)}')

path = tree_clf.cost_complexity_pruning_path(X_train, y_train)
ccp_alphas, impurities = path.ccp_alphas, path.impurities
print(ccp_alphas[1:20], len(ccp_alphas))

result = np.random.randint(len(ccp_alphas), size = (20))
result
#ccp_alphas = [ccp_alphas[x] for x in result ]
#ccp_alphas
result_sorted = []
for i in range(len(ccp_alphas)):
  for x in result:
   if i==x:
     result_sorted.append(ccp_alphas[x])


ccp_alphas=result_sorted

clfs = []
for ccp_alpha in ccp_alphas:
    clf = DecisionTreeClassifier(random_state=0, ccp_alpha=ccp_alpha)
    clf.fit(X_train, y_train)
    clfs.append(clf)

import matplotlib.pyplot as plt
clfs = clfs[:-1]
ccp_alphas = ccp_alphas[:-1]
node_counts = [clf.tree_.node_count for clf in clfs]
depth = [clf.tree_.max_depth for clf in clfs]
plt.scatter(ccp_alphas,node_counts)
plt.scatter(ccp_alphas,depth)
plt.plot(ccp_alphas,node_counts,label='no of nodes',drawstyle="steps-post")
plt.plot(ccp_alphas,depth,label='depth',drawstyle="steps-post")
plt.legend()
plt.show()

from sklearn.metrics import accuracy_score
from sklearn.metrics import confusion_matrix


train_acc = []
test_acc = []
for c in clfs:
    y_train_pred = c.predict(X_train)
    y_test_pred = c.predict(X_test)
    train_acc.append(accuracy_score(y_train_pred,y_train))
    test_acc.append(accuracy_score(y_test_pred,y_test))

plt.scatter(ccp_alphas,train_acc)
plt.scatter(ccp_alphas,test_acc)
plt.plot(ccp_alphas,train_acc,label='train_accuracy',drawstyle="steps-post")
plt.plot(ccp_alphas,test_acc,label='test_accuracy',drawstyle="steps-post")
plt.legend()
plt.title('Accuracy vs alpha')
plt.show()

clf_ = DecisionTreeClassifier(random_state=0,ccp_alpha=0.00035)
clf_.fit(X_train,y_train)
y_train_pred = clf_.predict(X_train)
y_test_pred = clf_.predict(X_test)

from sklearn.metrics import accuracy_score
from sklearn.metrics import confusion_matrix

y_test_pred = clf_.predict(X_test)
y_train_pred = clf_.predict(X_train)
confusion_matrix_valid = confusion_matrix(y_test, y_test_pred)
print(confusion_matrix_valid) 
print(f'Train score {accuracy_score(y_train_pred,y_train)}')
print(f'Test score {accuracy_score(y_test_pred,y_test)}')

clf_ = DecisionTreeClassifier(random_state=0,ccp_alpha=0.0004)
clf_.fit(X_train,y_train)
y_train_pred = clf_.predict(X_train)
y_test_pred = clf_.predict(X_test)

from sklearn.metrics import accuracy_score
from sklearn.metrics import confusion_matrix

y_test_pred = clf_.predict(X_test)
y_train_pred = clf_.predict(X_train)
confusion_matrix_valid = confusion_matrix(y_test, y_test_pred)
print(confusion_matrix_valid) 
print(f'Train score {accuracy_score(y_train_pred,y_train)}')
print(f'Test score {accuracy_score(y_test_pred,y_test)}')

"""### **Neural Networks**"""

from tensorflow import keras
model = keras.models.Sequential([   
    keras.layers.Dense(300, activation="relu"),
    keras.layers.Dense(100, activation="relu"),
    keras.layers.Dense(2, activation="sigmoid")
])

model.compile(loss="sparse_categorical_crossentropy",
              optimizer="sgd",
              metrics=["accuracy"])
history = model.fit(X_train, y_train, epochs=30)

model.evaluate(X_test, y_test)

from tensorflow.keras.optimizers import SGD, Adam, Adagrad, RMSprop
import tensorflow.keras.backend as K

dflist = []

optimizers = ['SGD(learning_rate=0.01)',
              'SGD(learning_rate=0.01, momentum=0.3)',
              'SGD(learning_rate=0.01, momentum=0.3, nesterov=True)',  
              'Adam(learning_rate=0.01)',
              'Adagrad(learning_rate=0.01)',
              'RMSprop(learning_rate=0.01)']

for opt_name in optimizers:

    K.clear_session()    
    model = keras.models.Sequential([   
    keras.layers.Dense(300, activation="relu"),
    keras.layers.Dense(100, activation="relu"),
    keras.layers.Dense(3, activation="sigmoid")])    
    model.compile(loss='sparse_categorical_crossentropy',
                  optimizer=eval(opt_name),
                  metrics=['accuracy'])
    h = model.fit(X_train, y_train, batch_size=16, epochs=5, verbose=0)    
    print(opt_name)
    print(model.evaluate(X_test, y_test))

from tensorflow.keras.optimizers import SGD, Adam, Adagrad, RMSprop
import tensorflow.keras.backend as K

dflist = []

batch_sizes = [16, 32, 64, 128,1000]

for batch_size in batch_sizes:
    K.clear_session()    
    model = keras.models.Sequential([   
    keras.layers.Dense(300, activation="relu"),
    keras.layers.Dense(100, activation="relu"),
    keras.layers.Dense(3, activation="sigmoid")])    

    model.compile(loss='sparse_categorical_crossentropy',
                  optimizer='sgd',
                  metrics=['accuracy'])
    h = model.fit(X_train, y_train, batch_size=batch_size, verbose=0, epochs=10)
    print(batch_size)
    print(model.evaluate(X_test, y_test))

from tensorflow import keras
from tensorflow.keras.layers import BatchNormalization
model = keras.models.Sequential([   
    keras.layers.Dense(300, activation="relu"),
    keras.layers.Dense(100, activation="relu"),
    keras.layers.Dense(3, activation="sigmoid")
])
model.add(BatchNormalization())
model.compile(loss="sparse_categorical_crossentropy",
              optimizer="sgd",
              metrics=["accuracy"])
history = model.fit(X_train, y_train, epochs=10)
model.evaluate(X_test, y_test)

dflist = []

learning_rates = [.001,0.01, 0.05, 0.1, 0.5,1]

for learning_rate in learning_rates:
    K.clear_session()    
    model = keras.models.Sequential([   
    keras.layers.Dense(300, activation="relu"),
    keras.layers.Dense(100, activation="relu"),
    keras.layers.Dense(3, activation="sigmoid")])    

    model.compile(loss='sparse_categorical_crossentropy',
                  optimizer=SGD(learning_rate=learning_rate),
                  metrics=['accuracy'])
    h = model.fit(X_train, y_train, batch_size=128, verbose=0, epochs=10)
    print(learning_rate)
    print(model.evaluate(X_test, y_test))

dflist = []

initializers = ['zeros', 
                'uniform', 
                'normal',
                'he_normal', 
                'lecun_uniform']

for initializers in initializers:
    K.clear_session()    
    model = keras.models.Sequential([   
    keras.layers.Dense(300, activation="relu",kernel_initializer=initializers),
    keras.layers.Dense(100, activation="relu"),
    keras.layers.Dense(3, activation="sigmoid")])    

    model.compile(loss='sparse_categorical_crossentropy',
                  optimizer=SGD(learning_rate=learning_rate),
                  metrics=['accuracy'])
    h = model.fit(X_train, y_train, batch_size=128, verbose=0, epochs=10)
    print(initializers)
    print(model.evaluate(X_test, y_test))

"""### **Boosting**"""

from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import AdaBoostClassifier

ada_clf = AdaBoostClassifier(
    DecisionTreeClassifier(max_depth=1), n_estimators=200,
    algorithm="SAMME.R", learning_rate=0.5, random_state=42)
ada_clf.fit(X_train, y_train)

from sklearn.metrics import accuracy_score
from sklearn.metrics import confusion_matrix

y_train_pred = ada_clf.predict(X_train)
y_test_pred = ada_clf.predict(X_test)

print(f'Train score {accuracy_score(y_train_pred,y_train)}')
print(f'Test score {accuracy_score(y_test_pred,y_test)}')

from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import AdaBoostClassifier

ada_clf = AdaBoostClassifier(
    DecisionTreeClassifier(max_depth=1), n_estimators=50,
    algorithm="SAMME.R", learning_rate=1, random_state=42)
ada_clf.fit(X_train, y_train)

y_train_pred = ada_clf.predict(X_train)
y_test_pred = ada_clf.predict(X_test)

print(f'Train score {accuracy_score(y_train_pred,y_train)}')
print(f'Test score {accuracy_score(y_test_pred,y_test)}')

from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import AdaBoostClassifier

ada_clf = AdaBoostClassifier(
    DecisionTreeClassifier(max_depth=1), n_estimators=100,
    algorithm="SAMME.R", learning_rate=5, random_state=42)
ada_clf.fit(X_train, y_train)

y_train_pred = ada_clf.predict(X_train)
y_test_pred = ada_clf.predict(X_test)

print(f'Train score {accuracy_score(y_train_pred,y_train)}')
print(f'Test score {accuracy_score(y_test_pred,y_test)}')

from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import AdaBoostClassifier

ada_clf = AdaBoostClassifier(
    DecisionTreeClassifier(max_depth=1), n_estimators=50,
    algorithm="SAMME.R", learning_rate=.01, random_state=42)
ada_clf.fit(X_train, y_train)

y_train_pred = ada_clf.predict(X_train)
y_test_pred = ada_clf.predict(X_test)

print(f'Train score {accuracy_score(y_train_pred,y_train)}')
print(f'Test score {accuracy_score(y_test_pred,y_test)}')

from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import AdaBoostClassifier

ada_clf = AdaBoostClassifier(
    DecisionTreeClassifier(max_depth=1), n_estimators=100,
    algorithm="SAMME.R", learning_rate=1, random_state=42)
ada_clf.fit(X_train, y_train)

y_train_pred = ada_clf.predict(X_train)
y_test_pred = ada_clf.predict(X_test)

print(f'Train score {accuracy_score(y_train_pred,y_train)}')
print(f'Test score {accuracy_score(y_test_pred,y_test)}')

"""https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html

### **SVM**
"""

from sklearn.svm import SVC

final = SVC()
final.fit(X_train, y_train)
y_train_pred= final.predict(X_train)
y_test_pred = final.predict(X_test)
from sklearn.metrics import confusion_matrix
from sklearn.metrics import accuracy_score

confusion_matrix_valid = confusion_matrix(y_test, y_test_pred)
print(confusion_matrix_valid) 
print(f'Train score {accuracy_score(y_train_pred,y_train)}')
print(f'Test score {accuracy_score(y_test_pred,y_test)}')

## Polynomial Kernel

from sklearn.svm import SVC
from sklearn.pipeline import Pipeline

poly100_kernel_svm_clf = Pipeline([
        ("svm_clf", SVC(kernel="poly", degree=2, coef0=100, C=5,cache_size=200000))
    ])
poly100_kernel_svm_clf.fit(X_train, y_train)

from sklearn.metrics import accuracy_score
from sklearn.metrics import confusion_matrix

y_test_pred = poly100_kernel_svm_clf.predict(X_test)
y_train_pred= poly100_kernel_svm_clf.predict(X_train)

from sklearn.metrics import confusion_matrix
from sklearn.metrics import accuracy_score

print(confusion_matrix_valid, accuracy_score) 
print(f'Train score {accuracy_score(y_train_pred,y_train)}')
print(f'Test score {accuracy_score(y_test_pred,y_test)}')

"""### **kNN**"""

from sklearn.neighbors import KNeighborsClassifier



knn = KNeighborsClassifier()
knn.fit(X_train,y_train)

from sklearn.metrics import accuracy_score
from sklearn.metrics import confusion_matrix

y_test_pred = knn.predict(X_test)
confusion_matrix_valid = confusion_matrix(y_test, y_test_pred)
accuracy_score = accuracy_score(y_test, y_test_pred)
print(confusion_matrix_valid, accuracy_score)

y_train_pred= knn.predict(X_train)

from sklearn.metrics import confusion_matrix
from sklearn.metrics import accuracy_score

print(confusion_matrix_valid, accuracy_score) 
print(f'Train score {accuracy_score(y_train_pred,y_train)}')
print(f'Test score {accuracy_score(y_test_pred,y_test)}')

from sklearn.neighbors import KNeighborsClassifier


param_knn = {}
param_knn['n_neighbors'] = 5
param_knn['leaf_size'] = 25

knn = KNeighborsClassifier(**param_knn)
knn.fit(X_train,y_train)

y_test_pred = knn.predict(X_test)
y_train_pred= knn.predict(X_train)

from sklearn.metrics import confusion_matrix
from sklearn.metrics import accuracy_score


print(f'Train score {accuracy_score(y_train_pred,y_train)}')
print(f'Test score {accuracy_score(y_test_pred,y_test)}')