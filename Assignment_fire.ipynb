{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment_fire.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "hzVNRDrCkmAR"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import os\n",
        "import random\n",
        "import scipy\n",
        "import seaborn as sns\n",
        "import math\n",
        "from scipy import stats\n",
        "import tensorflow as tf"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92U28ip2_NWN",
        "outputId": "7e2dd247-913f-4676-f33e-19778baec85c"
      },
      "source": [
        "import sys\n",
        "print(sys.version)\n",
        "print(tf.__version__)\n",
        "pd.show_versions()"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.7.12 (default, Sep 10 2021, 00:21:48) \n",
            "[GCC 7.5.0]\n",
            "2.6.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/psycopg2/__init__.py:144: UserWarning: The psycopg2 wheel package will be renamed from release 2.8; in order to keep installing from binary please use \"pip install psycopg2-binary\" instead. For details see: <http://initd.org/psycopg/docs/install.html#binary-install-from-pypi>.\n",
            "  \"\"\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "INSTALLED VERSIONS\n",
            "------------------\n",
            "commit           : b5958ee1999e9aead1938c0bba2b674378807b3d\n",
            "python           : 3.7.12.final.0\n",
            "python-bits      : 64\n",
            "OS               : Linux\n",
            "OS-release       : 5.4.104+\n",
            "Version          : #1 SMP Sat Jun 5 09:50:34 PDT 2021\n",
            "machine          : x86_64\n",
            "processor        : x86_64\n",
            "byteorder        : little\n",
            "LC_ALL           : None\n",
            "LANG             : en_US.UTF-8\n",
            "LOCALE           : en_US.UTF-8\n",
            "\n",
            "pandas           : 1.1.5\n",
            "numpy            : 1.19.5\n",
            "pytz             : 2018.9\n",
            "dateutil         : 2.8.2\n",
            "pip              : 21.1.3\n",
            "setuptools       : 57.4.0\n",
            "Cython           : 0.29.24\n",
            "pytest           : 3.6.4\n",
            "hypothesis       : None\n",
            "sphinx           : 1.8.5\n",
            "blosc            : None\n",
            "feather          : 0.4.1\n",
            "xlsxwriter       : None\n",
            "lxml.etree       : 4.2.6\n",
            "html5lib         : 1.0.1\n",
            "pymysql          : None\n",
            "psycopg2         : 2.7.6.1 (dt dec pq3 ext lo64)\n",
            "jinja2           : 2.11.3\n",
            "IPython          : 5.5.0\n",
            "pandas_datareader: 0.9.0\n",
            "bs4              : 4.6.3\n",
            "bottleneck       : 1.3.2\n",
            "fsspec           : None\n",
            "fastparquet      : None\n",
            "gcsfs            : None\n",
            "matplotlib       : 3.2.2\n",
            "numexpr          : 2.7.3\n",
            "odfpy            : None\n",
            "openpyxl         : 2.5.9\n",
            "pandas_gbq       : 0.13.3\n",
            "pyarrow          : 3.0.0\n",
            "pytables         : None\n",
            "pyxlsb           : None\n",
            "s3fs             : None\n",
            "scipy            : 1.4.1\n",
            "sqlalchemy       : 1.4.23\n",
            "tables           : 3.4.4\n",
            "tabulate         : 0.8.9\n",
            "xarray           : 0.18.2\n",
            "xlrd             : 1.1.0\n",
            "xlwt             : 1.3.0\n",
            "numba            : 0.51.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DO7DJsnMD5oZ"
      },
      "source": [
        "### **Data Processing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "wbmzAmNUk6Ca",
        "outputId": "ae1102a4-bd21-40cb-8248-97cf9e58438f"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-de9ecf0a-b640-49bd-9061-9330c5845444\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-de9ecf0a-b640-49bd-9061-9330c5845444\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Fire_data.csv to Fire_data.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "id": "7cv7-4QGk3Pa",
        "outputId": "7b25909e-78e7-41bf-e70d-62e6b284b108"
      },
      "source": [
        "df = pd.read_csv('Fire_data.csv')\n",
        "df2=df.copy()\n",
        "df2.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>latitude</th>\n",
              "      <th>longitude</th>\n",
              "      <th>quarter</th>\n",
              "      <th>year</th>\n",
              "      <th>sum_etage_hors_sol</th>\n",
              "      <th>sum_nombre_logement</th>\n",
              "      <th>nombre_logement_per_population</th>\n",
              "      <th>avg_annee_construction</th>\n",
              "      <th>sum_superficie_terrain</th>\n",
              "      <th>area</th>\n",
              "      <th>area_per_population</th>\n",
              "      <th>population</th>\n",
              "      <th>dwellings</th>\n",
              "      <th>dwellings_per_population</th>\n",
              "      <th>households</th>\n",
              "      <th>households_per_population</th>\n",
              "      <th>averagehouseholdsize</th>\n",
              "      <th>averageage</th>\n",
              "      <th>averagesizeofcensusfamilies</th>\n",
              "      <th>workers</th>\n",
              "      <th>workers_per_population</th>\n",
              "      <th>caserne_count</th>\n",
              "      <th>incendie_count</th>\n",
              "      <th>sum_superficie_batiment</th>\n",
              "      <th>superficie_batiment_per_population</th>\n",
              "      <th>incendie_count_last_100</th>\n",
              "      <th>incendie_count_last_300</th>\n",
              "      <th>alarm_incendie_count_last_100</th>\n",
              "      <th>total_crimes_last_100</th>\n",
              "      <th>vols_count_last_100</th>\n",
              "      <th>mefait_count_last_100</th>\n",
              "      <th>vol_de_vehicule_count_last_100</th>\n",
              "      <th>introduction_count_last_100</th>\n",
              "      <th>infractions_entrainant_count_last_100</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>45.40</td>\n",
              "      <td>-73.96</td>\n",
              "      <td>2</td>\n",
              "      <td>2017</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1900.00</td>\n",
              "      <td>2732</td>\n",
              "      <td>1.57174</td>\n",
              "      <td>0.004465</td>\n",
              "      <td>352</td>\n",
              "      <td>162</td>\n",
              "      <td>0.460227</td>\n",
              "      <td>149</td>\n",
              "      <td>0.423295</td>\n",
              "      <td>2.3</td>\n",
              "      <td>42.0</td>\n",
              "      <td>2.7</td>\n",
              "      <td>100</td>\n",
              "      <td>0.284091</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>831</td>\n",
              "      <td>2.360795</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>45.40</td>\n",
              "      <td>-73.96</td>\n",
              "      <td>3</td>\n",
              "      <td>2019</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1900.00</td>\n",
              "      <td>2732</td>\n",
              "      <td>1.57174</td>\n",
              "      <td>0.004465</td>\n",
              "      <td>352</td>\n",
              "      <td>162</td>\n",
              "      <td>0.460227</td>\n",
              "      <td>149</td>\n",
              "      <td>0.423295</td>\n",
              "      <td>2.3</td>\n",
              "      <td>42.0</td>\n",
              "      <td>2.7</td>\n",
              "      <td>100</td>\n",
              "      <td>0.284091</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>831</td>\n",
              "      <td>2.360795</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>45.41</td>\n",
              "      <td>-73.95</td>\n",
              "      <td>1</td>\n",
              "      <td>2015</td>\n",
              "      <td>728</td>\n",
              "      <td>730</td>\n",
              "      <td>2.324841</td>\n",
              "      <td>1949.98</td>\n",
              "      <td>253537</td>\n",
              "      <td>0.21093</td>\n",
              "      <td>0.000672</td>\n",
              "      <td>314</td>\n",
              "      <td>7</td>\n",
              "      <td>0.022293</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>91.6</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>80990</td>\n",
              "      <td>257.929936</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>45.41</td>\n",
              "      <td>-73.95</td>\n",
              "      <td>2</td>\n",
              "      <td>2015</td>\n",
              "      <td>728</td>\n",
              "      <td>730</td>\n",
              "      <td>2.324841</td>\n",
              "      <td>1949.98</td>\n",
              "      <td>253537</td>\n",
              "      <td>0.21093</td>\n",
              "      <td>0.000672</td>\n",
              "      <td>314</td>\n",
              "      <td>7</td>\n",
              "      <td>0.022293</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>91.6</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>80990</td>\n",
              "      <td>257.929936</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>45.41</td>\n",
              "      <td>-73.95</td>\n",
              "      <td>3</td>\n",
              "      <td>2015</td>\n",
              "      <td>728</td>\n",
              "      <td>730</td>\n",
              "      <td>2.324841</td>\n",
              "      <td>1949.98</td>\n",
              "      <td>253537</td>\n",
              "      <td>0.21093</td>\n",
              "      <td>0.000672</td>\n",
              "      <td>314</td>\n",
              "      <td>7</td>\n",
              "      <td>0.022293</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>91.6</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>80990</td>\n",
              "      <td>257.929936</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>45.41</td>\n",
              "      <td>-73.95</td>\n",
              "      <td>4</td>\n",
              "      <td>2015</td>\n",
              "      <td>728</td>\n",
              "      <td>730</td>\n",
              "      <td>2.324841</td>\n",
              "      <td>1949.98</td>\n",
              "      <td>253537</td>\n",
              "      <td>0.21093</td>\n",
              "      <td>0.000672</td>\n",
              "      <td>314</td>\n",
              "      <td>7</td>\n",
              "      <td>0.022293</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>91.6</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>80990</td>\n",
              "      <td>257.929936</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>45.41</td>\n",
              "      <td>-73.95</td>\n",
              "      <td>1</td>\n",
              "      <td>2016</td>\n",
              "      <td>728</td>\n",
              "      <td>730</td>\n",
              "      <td>2.324841</td>\n",
              "      <td>1949.98</td>\n",
              "      <td>253537</td>\n",
              "      <td>0.21093</td>\n",
              "      <td>0.000672</td>\n",
              "      <td>314</td>\n",
              "      <td>7</td>\n",
              "      <td>0.022293</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>91.6</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>80990</td>\n",
              "      <td>257.929936</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>45.41</td>\n",
              "      <td>-73.95</td>\n",
              "      <td>2</td>\n",
              "      <td>2016</td>\n",
              "      <td>728</td>\n",
              "      <td>730</td>\n",
              "      <td>2.324841</td>\n",
              "      <td>1949.98</td>\n",
              "      <td>253537</td>\n",
              "      <td>0.21093</td>\n",
              "      <td>0.000672</td>\n",
              "      <td>314</td>\n",
              "      <td>7</td>\n",
              "      <td>0.022293</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>91.6</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>80990</td>\n",
              "      <td>257.929936</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>45.41</td>\n",
              "      <td>-73.95</td>\n",
              "      <td>3</td>\n",
              "      <td>2016</td>\n",
              "      <td>728</td>\n",
              "      <td>730</td>\n",
              "      <td>2.324841</td>\n",
              "      <td>1949.98</td>\n",
              "      <td>253537</td>\n",
              "      <td>0.21093</td>\n",
              "      <td>0.000672</td>\n",
              "      <td>314</td>\n",
              "      <td>7</td>\n",
              "      <td>0.022293</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>91.6</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>80990</td>\n",
              "      <td>257.929936</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>45.41</td>\n",
              "      <td>-73.95</td>\n",
              "      <td>4</td>\n",
              "      <td>2016</td>\n",
              "      <td>728</td>\n",
              "      <td>730</td>\n",
              "      <td>2.324841</td>\n",
              "      <td>1949.98</td>\n",
              "      <td>253537</td>\n",
              "      <td>0.21093</td>\n",
              "      <td>0.000672</td>\n",
              "      <td>314</td>\n",
              "      <td>7</td>\n",
              "      <td>0.022293</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>91.6</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>80990</td>\n",
              "      <td>257.929936</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   latitude  ...  infractions_entrainant_count_last_100\n",
              "0     45.40  ...                                      0\n",
              "1     45.40  ...                                      0\n",
              "2     45.41  ...                                      0\n",
              "3     45.41  ...                                      0\n",
              "4     45.41  ...                                      0\n",
              "5     45.41  ...                                      0\n",
              "6     45.41  ...                                      0\n",
              "7     45.41  ...                                      0\n",
              "8     45.41  ...                                      0\n",
              "9     45.41  ...                                      0\n",
              "\n",
              "[10 rows x 34 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mxHUGcavk-8v",
        "outputId": "dce8c27f-5674-4bcc-cdf0-2e0752f27bae"
      },
      "source": [
        "!pip install geopy \n",
        "import geopy.distance\n",
        "\n",
        "def dist(x,y):\n",
        "  coords_1 = (45.504654, -73.56546)\n",
        "  coords_2 = (x, y)\n",
        "  return geopy.distance.distance(coords_1, coords_2).km\n",
        "\n",
        "df2['distance']=0\n",
        "\n",
        "for i in range(0,len(df2)-1):\n",
        "  df2['distance'][i]=dist(df2['latitude'][i], df2['longitude'][i])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: geopy in /usr/local/lib/python3.7/dist-packages (1.17.0)\n",
            "Requirement already satisfied: geographiclib<2,>=1.49 in /usr/local/lib/python3.7/dist-packages (from geopy) (1.52)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if sys.path[0] == '':\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g-hODrw0lD4Z",
        "outputId": "1b3b2b04-59d2-47d2-842c-e08924199820"
      },
      "source": [
        "df2['fire'] = df2['incendie_count']\n",
        "df2['fire'][df2['incendie_count']==0] = 0\n",
        "df2['fire'][(df2['incendie_count']==1)] = 1\n",
        "df2['fire'][df2['incendie_count']>=2] = 2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  after removing the cwd from sys.path.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p2K6eRLtlI7L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d5f6f29-0cbf-469b-922b-15a7445f45b6"
      },
      "source": [
        "df2 = df2.drop(\"latitude\", axis=1)\n",
        "df2 = df2.drop(\"longitude\", axis=1)      \n",
        "df2 = df2.drop(\"incendie_count\", axis=1)\n",
        "df3 = df2.drop(\"year\",axis=1)\n",
        "df3 = df3.drop(\"quarter\",axis=1)\n",
        "df2['fire'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    7633\n",
              "1    2644\n",
              "2    1566\n",
              "Name: fire, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O-F-4IKAlL9J",
        "outputId": "b59e2a97-e372-4dc7-9444-68c21f18825a"
      },
      "source": [
        "corr_matrix = df2.corr()\n",
        "X_raw=df3.drop(\"fire\", axis=1)\n",
        "corr_matrix[\"fire\"].sort_values(ascending=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "fire                                     1.000000\n",
              "incendie_count_last_100                  0.505725\n",
              "sum_nombre_logement                      0.503540\n",
              "incendie_count_last_300                  0.489631\n",
              "sum_etage_hors_sol                       0.445073\n",
              "total_crimes_last_100                    0.432339\n",
              "introduction_count_last_100              0.404394\n",
              "mefait_count_last_100                    0.403223\n",
              "alarm_incendie_count_last_100            0.397760\n",
              "vols_count_last_100                      0.321872\n",
              "vol_de_vehicule_count_last_100           0.218539\n",
              "households_per_population                0.202810\n",
              "caserne_count                            0.163537\n",
              "dwellings_per_population                 0.153500\n",
              "sum_superficie_batiment                  0.133144\n",
              "sum_superficie_terrain                   0.085039\n",
              "dwellings                                0.067331\n",
              "infractions_entrainant_count_last_100    0.063383\n",
              "households                               0.040217\n",
              "nombre_logement_per_population           0.025062\n",
              "superficie_batiment_per_population       0.022907\n",
              "area_per_population                     -0.005304\n",
              "year                                    -0.010462\n",
              "quarter                                 -0.034149\n",
              "averageage                              -0.041041\n",
              "population                              -0.052815\n",
              "averagesizeofcensusfamilies             -0.070708\n",
              "workers                                 -0.084697\n",
              "workers_per_population                  -0.096410\n",
              "averagehouseholdsize                    -0.173379\n",
              "area                                    -0.207958\n",
              "avg_annee_construction                  -0.220145\n",
              "distance                                -0.353648\n",
              "Name: fire, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vC9eHnZHlRir"
      },
      "source": [
        "from sklearn import preprocessing\n",
        "\n",
        "# standardize X and y before fitting multiple linear model\n",
        "X = pd.DataFrame(preprocessing.scale(X_raw))\n",
        "y = df3['fire'].copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-tsN4ZSlUEt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46df18f5-7e53-413f-a07c-4e45f885bddf"
      },
      "source": [
        "X_train = X[df2['year'] < 2019]\n",
        "y_train = y[df2['year'] < 2019]\n",
        "\n",
        "X_test = X[(df2['year']==2019) & (df2['quarter']==1)]\n",
        "y_test = y[(df2['year']==2019) & (df2['quarter']==1)]\n",
        "len(X_train),len(y_train),len(X_test),len(y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7999, 7999, 494, 494)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jjjecAru9CHF"
      },
      "source": [
        "### **Decision Tree**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cwsaQXhylcNJ",
        "outputId": "0ff3d84b-a6fb-4523-e28b-b514e22694b9"
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "tree_clf = DecisionTreeClassifier()\n",
        "tree_clf.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
              "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
              "                       random_state=None, splitter='best')"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "11pW3zW4ligF",
        "outputId": "163488f1-43ff-4620-d15f-3159e4345579"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "y_test_pred = tree_clf.predict(X_test)\n",
        "confusion_matrix_valid = confusion_matrix(y_test, y_test_pred)\n",
        "print(confusion_matrix_valid) \n",
        "y_train_pred = tree_clf.predict(X_train)\n",
        "print(f'Train score {accuracy_score(y_train_pred,y_train)}')\n",
        "print(f'Test score {accuracy_score(y_test_pred,y_test)}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[224  74  18]\n",
            " [ 66  30  13]\n",
            " [ 25  19  25]]\n",
            "Train score 0.9968746093261658\n",
            "Test score 0.5647773279352226\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ImCWzGhflljn",
        "outputId": "7fcb645e-eb7a-4f93-a821-2f2d4af259e5"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV \n",
        "\n",
        "\n",
        "\n",
        "param_test1 = {\n",
        "  'max_depth':(2,6,10,100,200,500,1000),\n",
        "  'max_features':(2,5,10,15,20,100),\n",
        "}\n",
        "gsearch1 = GridSearchCV(estimator = DecisionTreeClassifier(), param_grid = param_test1,scoring='accuracy', n_jobs=4, cv=5)\n",
        "gsearch1.fit(X_train, y_train)\n",
        "gsearch1.cv_results_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'mean_fit_time': array([0.02005153, 0.02261953, 0.0266984 , 0.03015084, 0.0389617 ,\n",
              "        0.00695763, 0.01054406, 0.02493205, 0.05304813, 0.07794189,\n",
              "        0.10103106, 0.00743799, 0.0216496 , 0.04350371, 0.09359584,\n",
              "        0.11549888, 0.16834073, 0.0138701 , 0.03786073, 0.078582  ,\n",
              "        0.11098223, 0.18344779, 0.23863306, 0.01232605, 0.044523  ,\n",
              "        0.06674256, 0.12554255, 0.19963059, 0.25215621, 0.01337128,\n",
              "        0.0364994 , 0.06812739, 0.1332242 , 0.17190003, 0.23823829,\n",
              "        0.01026888, 0.04519072, 0.07181196, 0.12842603, 0.15732732,\n",
              "        0.18296142, 0.00963888]),\n",
              " 'mean_score_time': array([0.00449343, 0.00345874, 0.0086484 , 0.00210099, 0.00189576,\n",
              "        0.        , 0.00191846, 0.00486784, 0.00549226, 0.00196381,\n",
              "        0.0067122 , 0.        , 0.00676317, 0.00305653, 0.00912709,\n",
              "        0.00571589, 0.00673013, 0.        , 0.00508547, 0.00734391,\n",
              "        0.00779881, 0.00622191, 0.00605054, 0.        , 0.00682597,\n",
              "        0.00698676, 0.0068295 , 0.00407066, 0.00484028, 0.        ,\n",
              "        0.00651174, 0.00657325, 0.00632343, 0.00545125, 0.00322561,\n",
              "        0.        , 0.00461955, 0.00474072, 0.00408635, 0.00506291,\n",
              "        0.00378304, 0.        ]),\n",
              " 'mean_test_score': array([0.63958099, 0.65395544, 0.6578324 , 0.6644574 , 0.6569574 ,\n",
              "               nan, 0.60520325, 0.59807935, 0.59620521, 0.59757896,\n",
              "        0.59270536,        nan, 0.52857942, 0.50857559, 0.50845138,\n",
              "        0.5017031 , 0.49920153,        nan, 0.40306879, 0.39381653,\n",
              "        0.4229427 , 0.40494074, 0.39519121,        nan, 0.42656809,\n",
              "        0.40281817, 0.41407137, 0.40231762, 0.41919426,        nan,\n",
              "        0.39656801, 0.38381746, 0.37931144, 0.42569356, 0.39981684,\n",
              "               nan, 0.39844309, 0.38781535, 0.41919606, 0.40744254,\n",
              "        0.40731442,        nan]),\n",
              " 'param_max_depth': masked_array(data=[2, 2, 2, 2, 2, 2, 6, 6, 6, 6, 6, 6, 10, 10, 10, 10, 10,\n",
              "                    10, 100, 100, 100, 100, 100, 100, 200, 200, 200, 200,\n",
              "                    200, 200, 500, 500, 500, 500, 500, 500, 1000, 1000,\n",
              "                    1000, 1000, 1000, 1000],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'param_max_features': masked_array(data=[2, 5, 10, 15, 20, 100, 2, 5, 10, 15, 20, 100, 2, 5, 10,\n",
              "                    15, 20, 100, 2, 5, 10, 15, 20, 100, 2, 5, 10, 15, 20,\n",
              "                    100, 2, 5, 10, 15, 20, 100, 2, 5, 10, 15, 20, 100],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'params': [{'max_depth': 2, 'max_features': 2},\n",
              "  {'max_depth': 2, 'max_features': 5},\n",
              "  {'max_depth': 2, 'max_features': 10},\n",
              "  {'max_depth': 2, 'max_features': 15},\n",
              "  {'max_depth': 2, 'max_features': 20},\n",
              "  {'max_depth': 2, 'max_features': 100},\n",
              "  {'max_depth': 6, 'max_features': 2},\n",
              "  {'max_depth': 6, 'max_features': 5},\n",
              "  {'max_depth': 6, 'max_features': 10},\n",
              "  {'max_depth': 6, 'max_features': 15},\n",
              "  {'max_depth': 6, 'max_features': 20},\n",
              "  {'max_depth': 6, 'max_features': 100},\n",
              "  {'max_depth': 10, 'max_features': 2},\n",
              "  {'max_depth': 10, 'max_features': 5},\n",
              "  {'max_depth': 10, 'max_features': 10},\n",
              "  {'max_depth': 10, 'max_features': 15},\n",
              "  {'max_depth': 10, 'max_features': 20},\n",
              "  {'max_depth': 10, 'max_features': 100},\n",
              "  {'max_depth': 100, 'max_features': 2},\n",
              "  {'max_depth': 100, 'max_features': 5},\n",
              "  {'max_depth': 100, 'max_features': 10},\n",
              "  {'max_depth': 100, 'max_features': 15},\n",
              "  {'max_depth': 100, 'max_features': 20},\n",
              "  {'max_depth': 100, 'max_features': 100},\n",
              "  {'max_depth': 200, 'max_features': 2},\n",
              "  {'max_depth': 200, 'max_features': 5},\n",
              "  {'max_depth': 200, 'max_features': 10},\n",
              "  {'max_depth': 200, 'max_features': 15},\n",
              "  {'max_depth': 200, 'max_features': 20},\n",
              "  {'max_depth': 200, 'max_features': 100},\n",
              "  {'max_depth': 500, 'max_features': 2},\n",
              "  {'max_depth': 500, 'max_features': 5},\n",
              "  {'max_depth': 500, 'max_features': 10},\n",
              "  {'max_depth': 500, 'max_features': 15},\n",
              "  {'max_depth': 500, 'max_features': 20},\n",
              "  {'max_depth': 500, 'max_features': 100},\n",
              "  {'max_depth': 1000, 'max_features': 2},\n",
              "  {'max_depth': 1000, 'max_features': 5},\n",
              "  {'max_depth': 1000, 'max_features': 10},\n",
              "  {'max_depth': 1000, 'max_features': 15},\n",
              "  {'max_depth': 1000, 'max_features': 20},\n",
              "  {'max_depth': 1000, 'max_features': 100}],\n",
              " 'rank_test_score': array([ 5,  4,  2,  1,  3, 37,  6,  7,  9,  8, 10, 39, 11, 12, 13, 14, 15,\n",
              "        38, 25, 32, 18, 24, 31, 40, 16, 26, 21, 27, 20, 36, 30, 34, 35, 17,\n",
              "        28, 41, 29, 33, 19, 22, 23, 42], dtype=int32),\n",
              " 'split0_test_score': array([0.639375, 0.645625, 0.6525  , 0.651875, 0.6575  ,      nan,\n",
              "        0.68    , 0.655625, 0.65    , 0.674375, 0.658125,      nan,\n",
              "        0.63    , 0.63125 , 0.628125, 0.654375, 0.63625 ,      nan,\n",
              "        0.5625  , 0.568125, 0.546875, 0.575   , 0.56125 ,      nan,\n",
              "        0.578125, 0.558125, 0.57875 , 0.551875, 0.5875  ,      nan,\n",
              "        0.579375, 0.591875, 0.541875, 0.5875  , 0.570625,      nan,\n",
              "        0.5675  , 0.559375, 0.603125, 0.578125, 0.53875 ,      nan]),\n",
              " 'split1_test_score': array([0.65875 , 0.689375, 0.6725  , 0.696875, 0.696875,      nan,\n",
              "        0.6     , 0.608125, 0.61125 , 0.595625, 0.596875,      nan,\n",
              "        0.50875 , 0.5125  , 0.518125, 0.439375, 0.435625,      nan,\n",
              "        0.37625 , 0.3275  , 0.378125, 0.335625, 0.323125,      nan,\n",
              "        0.413125, 0.344375, 0.340625, 0.311875, 0.381875,      nan,\n",
              "        0.286875, 0.32    , 0.279375, 0.328125, 0.29625 ,      nan,\n",
              "        0.40125 , 0.3025  , 0.355625, 0.296875, 0.366875,      nan]),\n",
              " 'split2_test_score': array([0.69125 , 0.6975  , 0.68125 , 0.6975  , 0.700625,      nan,\n",
              "        0.630625, 0.58625 , 0.5775  , 0.559375, 0.565   ,      nan,\n",
              "        0.44875 , 0.43625 , 0.37125 , 0.416875, 0.404375,      nan,\n",
              "        0.2825  , 0.249375, 0.354375, 0.279375, 0.27    ,      nan,\n",
              "        0.30875 , 0.324375, 0.266875, 0.304375, 0.26875 ,      nan,\n",
              "        0.25875 , 0.161875, 0.303125, 0.336875, 0.28625 ,      nan,\n",
              "        0.24375 , 0.264375, 0.2725  , 0.330625, 0.32375 ,      nan]),\n",
              " 'split3_test_score': array([0.560625, 0.59375 , 0.62375 , 0.616875, 0.570625,      nan,\n",
              "        0.489375, 0.505625, 0.500625, 0.526875, 0.500625,      nan,\n",
              "        0.42    , 0.358125, 0.41375 , 0.373125, 0.4075  ,      nan,\n",
              "        0.24375 , 0.291875, 0.29375 , 0.30875 , 0.291875,      nan,\n",
              "        0.288125, 0.241875, 0.313125, 0.3025  , 0.30375 ,      nan,\n",
              "        0.31375 , 0.305625, 0.280625, 0.3275  , 0.31125 ,      nan,\n",
              "        0.235   , 0.29    , 0.29625 , 0.29125 , 0.291875,      nan]),\n",
              " 'split4_test_score': array([0.64790494, 0.6435272 , 0.65916198, 0.65916198, 0.65916198,\n",
              "               nan, 0.62601626, 0.63477173, 0.64165103, 0.63164478,\n",
              "        0.64290181,        nan, 0.63539712, 0.60475297, 0.61100688,\n",
              "        0.62476548, 0.61225766,        nan, 0.55034396, 0.53220763,\n",
              "        0.54158849, 0.52595372, 0.52970607,        nan, 0.54471545,\n",
              "        0.54534084, 0.57098186, 0.5409631 , 0.55409631,        nan,\n",
              "        0.54409006, 0.53971232, 0.49155722, 0.54846779, 0.53470919,\n",
              "               nan, 0.54471545, 0.52282677, 0.5684803 , 0.54033771,\n",
              "        0.51532208,        nan]),\n",
              " 'std_fit_time': array([0.00472771, 0.00569378, 0.00392208, 0.00937832, 0.00954469,\n",
              "        0.00321654, 0.00204931, 0.00801007, 0.00877752, 0.00909178,\n",
              "        0.00611422, 0.00326525, 0.00737963, 0.00356483, 0.00821101,\n",
              "        0.01659875, 0.02070087, 0.00223905, 0.01731656, 0.01493914,\n",
              "        0.0331672 , 0.05478956, 0.02184917, 0.00043449, 0.00706821,\n",
              "        0.00521196, 0.01294416, 0.01496886, 0.01569168, 0.0065068 ,\n",
              "        0.01608126, 0.0164407 , 0.01104336, 0.03047625, 0.01396532,\n",
              "        0.00443359, 0.00749762, 0.00608527, 0.03104928, 0.0472832 ,\n",
              "        0.05910823, 0.00371004]),\n",
              " 'std_score_time': array([2.63018376e-03, 1.40714074e-03, 3.61874323e-03, 1.99439124e-04,\n",
              "        4.78533113e-05, 0.00000000e+00, 3.05110954e-05, 5.15123775e-03,\n",
              "        3.23948005e-03, 1.05860899e-04, 2.57702401e-03, 0.00000000e+00,\n",
              "        3.92390369e-03, 1.91373225e-03, 3.64539767e-03, 4.12369087e-03,\n",
              "        5.43451689e-03, 0.00000000e+00, 4.71825679e-03, 4.07251478e-03,\n",
              "        4.16192635e-03, 4.32781684e-03, 4.11739475e-03, 0.00000000e+00,\n",
              "        2.75415177e-03, 3.65783403e-03, 5.42924831e-03, 2.94619111e-03,\n",
              "        3.15119430e-03, 0.00000000e+00, 3.86552888e-03, 3.29936976e-03,\n",
              "        3.12976502e-03, 2.71637244e-03, 1.24229387e-03, 0.00000000e+00,\n",
              "        2.81080133e-03, 4.06107952e-03, 2.89155956e-03, 3.01220467e-03,\n",
              "        3.10693679e-03, 0.00000000e+00]),\n",
              " 'std_test_score': array([0.04322156, 0.03729213, 0.01977541, 0.03030893, 0.04681605,\n",
              "               nan, 0.06343068, 0.05185844, 0.05416827, 0.052001  ,\n",
              "        0.05668012,        nan, 0.08972356, 0.1021576 , 0.10268939,\n",
              "        0.11494867, 0.10296328,        nan, 0.13247403, 0.13052881,\n",
              "        0.10279781, 0.12115146, 0.12426615,        nan, 0.11845388,\n",
              "        0.12641563, 0.13341009, 0.11775072, 0.1295214 ,        nan,\n",
              "        0.13643045, 0.15939657, 0.11362808, 0.11688043, 0.12556988,\n",
              "               nan, 0.14186424, 0.12628925, 0.13913475, 0.12523614,\n",
              "        0.1008817 ,        nan])}"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ALk3S0PXlpWr"
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "tree_clf = DecisionTreeClassifier(max_depth=6,max_features=10)\n",
        "tree_clf.fit(X_train, y_train)\n",
        "y_test_pred = tree_clf.predict(X_test)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F9C0DLqXlt-b",
        "outputId": "2f6495a5-80c2-4046-9654-ba1f12933cb7"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "y_test_pred = tree_clf.predict(X_test)\n",
        "confusion_matrix_valid = confusion_matrix(y_test, y_test_pred)\n",
        "print(confusion_matrix_valid) \n",
        "y_train_pred = tree_clf.predict(X_train)\n",
        "print(f'Train score {accuracy_score(y_train_pred,y_train)}')\n",
        "print(f'Test score {accuracy_score(y_test_pred,y_test)}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[283  21  12]\n",
            " [ 71  25  13]\n",
            " [ 26  13  30]]\n",
            "Train score 0.6977122140267533\n",
            "Test score 0.6842105263157895\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HX3HNpKklwnB",
        "outputId": "149aaf27-a932-4f68-afe9-21ea0c8f9819"
      },
      "source": [
        "path = tree_clf.cost_complexity_pruning_path(X_train, y_train)\n",
        "ccp_alphas, impurities = path.ccp_alphas, path.impurities\n",
        "print(ccp_alphas)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.00000000e+00 4.24295461e-05 1.53954429e-04 1.68026956e-04\n",
            " 1.78452641e-04 1.81858402e-04 2.00574522e-04 2.07137961e-04\n",
            " 2.27686507e-04 2.30235256e-04 2.63921879e-04 2.65219556e-04\n",
            " 2.65971316e-04 2.82442713e-04 3.05395317e-04 3.34676073e-04\n",
            " 3.51752306e-04 3.52518446e-04 3.98008935e-04 3.98849018e-04\n",
            " 4.05106327e-04 4.13061281e-04 4.72712263e-04 4.73288824e-04\n",
            " 4.77191378e-04 4.91549217e-04 4.92101179e-04 5.30384356e-04\n",
            " 5.43141086e-04 5.81301242e-04 5.81592515e-04 5.88265107e-04\n",
            " 5.90199435e-04 6.00561315e-04 6.17975884e-04 6.70915300e-04\n",
            " 6.91284343e-04 7.27858098e-04 7.33158237e-04 8.21258663e-04\n",
            " 8.35678794e-04 8.92695214e-04 1.04459315e-03 1.14486331e-03\n",
            " 1.24799621e-03 1.28901719e-03 2.62326199e-03 4.48562361e-03\n",
            " 5.04427882e-03 7.75111158e-03 9.20796294e-03 1.37205391e-02\n",
            " 5.58333590e-02]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7S1yCUnelzBg"
      },
      "source": [
        "# For each alpha we will append our model to a list\n",
        "clfs = []\n",
        "for ccp_alpha in ccp_alphas:\n",
        "    clf = DecisionTreeClassifier(random_state=0, ccp_alpha=ccp_alpha)\n",
        "    clf.fit(X_train, y_train)\n",
        "    clfs.append(clf)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 264
        },
        "id": "KrZLiFuXl3WX",
        "outputId": "d6d26d1a-d86e-433c-d1ef-a76bd921bc4b"
      },
      "source": [
        "clfs = clfs[:-1]\n",
        "ccp_alphas = ccp_alphas[:-1]\n",
        "node_counts = [clf.tree_.node_count for clf in clfs]\n",
        "depth = [clf.tree_.max_depth for clf in clfs]\n",
        "plt.scatter(ccp_alphas,node_counts)\n",
        "plt.scatter(ccp_alphas,depth)\n",
        "plt.plot(ccp_alphas,node_counts,label='no of nodes',drawstyle=\"steps-post\")\n",
        "plt.plot(ccp_alphas,depth,label='depth',drawstyle=\"steps-post\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "yKWakTLhl5xE",
        "outputId": "683ebbf3-58b1-4f6f-f66b-b1707526aa56"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "\n",
        "train_acc = []\n",
        "test_acc = []\n",
        "for c in clfs:\n",
        "    y_train_pred = c.predict(X_train)\n",
        "    y_test_pred = c.predict(X_test)\n",
        "    train_acc.append(accuracy_score(y_train_pred,y_train))\n",
        "    test_acc.append(accuracy_score(y_test_pred,y_test))\n",
        "\n",
        "plt.scatter(ccp_alphas,train_acc)\n",
        "plt.scatter(ccp_alphas,test_acc)\n",
        "plt.plot(ccp_alphas,train_acc,label='train_accuracy',drawstyle=\"steps-post\")\n",
        "plt.plot(ccp_alphas,test_acc,label='test_accuracy',drawstyle=\"steps-post\")\n",
        "plt.legend()\n",
        "plt.title('Accuracy vs alpha')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SBeddZJJl8Hy",
        "outputId": "e9f8c7c2-0b5d-4ed5-f59a-44c026844185"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "clf_ = DecisionTreeClassifier(random_state=0,ccp_alpha=0.0025)\n",
        "clf_.fit(X_train,y_train)\n",
        "y_train_pred = clf_.predict(X_train)\n",
        "y_test_pred = clf_.predict(X_test)\n",
        "\n",
        "print(f'Train score {accuracy_score(y_train_pred,y_train)}')\n",
        "print(f'Test score {accuracy_score(y_test_pred,y_test)}')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train score 0.6788348543567946\n",
            "Test score 0.6923076923076923\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FBhhOPVGQ41J",
        "outputId": "4954c465-bd25-4ffb-8674-f2cf1ebd7036"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "y_test_pred = clf_.predict(X_test)\n",
        "confusion_matrix_valid = confusion_matrix(y_test, y_test_pred)\n",
        "accuracy_score = accuracy_score(y_test, y_test_pred)\n",
        "print(confusion_matrix_valid, accuracy_score) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[302   0  14]\n",
            " [ 91   0  18]\n",
            " [ 29   0  40]] 0.6923076923076923\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D-2OEaKzmAO6"
      },
      "source": [
        "https://www.kaggle.com/arunmohan003/pruning-decision-trees-tutorial"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QdENjsqYUo-I"
      },
      "source": [
        "### **Neural Network**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TBLZiE-EUnfO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6db00b4c-1930-4e01-dccb-6aeeb97cee33"
      },
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "model = keras.models.Sequential([   \n",
        "    keras.layers.Dense(300, activation=\"relu\"),\n",
        "    keras.layers.Dense(100, activation=\"relu\"),\n",
        "    keras.layers.Dense(3, activation=\"sigmoid\")\n",
        "])\n",
        "\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "              optimizer=\"sgd\",\n",
        "              metrics=[\"accuracy\"])\n",
        "history = model.fit(X_train, y_train, epochs=30)\n",
        "model.evaluate(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.7938 - accuracy: 0.6566\n",
            "Epoch 2/30\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.7227 - accuracy: 0.6848\n",
            "Epoch 3/30\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.7120 - accuracy: 0.6871\n",
            "Epoch 4/30\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.7063 - accuracy: 0.6908\n",
            "Epoch 5/30\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.7022 - accuracy: 0.6885\n",
            "Epoch 6/30\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.7002 - accuracy: 0.6888\n",
            "Epoch 7/30\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.6980 - accuracy: 0.6888\n",
            "Epoch 8/30\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.6955 - accuracy: 0.6912\n",
            "Epoch 9/30\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.6939 - accuracy: 0.6918\n",
            "Epoch 10/30\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.6928 - accuracy: 0.6915\n",
            "Epoch 11/30\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.6912 - accuracy: 0.6916\n",
            "Epoch 12/30\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.6896 - accuracy: 0.6938\n",
            "Epoch 13/30\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.6887 - accuracy: 0.6955\n",
            "Epoch 14/30\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.6879 - accuracy: 0.6917\n",
            "Epoch 15/30\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.6865 - accuracy: 0.6930\n",
            "Epoch 16/30\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.6859 - accuracy: 0.6938\n",
            "Epoch 17/30\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.6847 - accuracy: 0.6945\n",
            "Epoch 18/30\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.6842 - accuracy: 0.6948\n",
            "Epoch 19/30\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.6830 - accuracy: 0.6973\n",
            "Epoch 20/30\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.6827 - accuracy: 0.6967\n",
            "Epoch 21/30\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.6811 - accuracy: 0.6983\n",
            "Epoch 22/30\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.6804 - accuracy: 0.6966\n",
            "Epoch 23/30\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.6793 - accuracy: 0.6977\n",
            "Epoch 24/30\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.6795 - accuracy: 0.6978\n",
            "Epoch 25/30\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.6786 - accuracy: 0.6981\n",
            "Epoch 26/30\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.6772 - accuracy: 0.7011\n",
            "Epoch 27/30\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.6772 - accuracy: 0.6997\n",
            "Epoch 28/30\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.6762 - accuracy: 0.6996\n",
            "Epoch 29/30\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.6754 - accuracy: 0.7005\n",
            "Epoch 30/30\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.6750 - accuracy: 0.7013\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.7294 - accuracy: 0.6862\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7294379472732544, 0.6862348318099976]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iqltmcbN5l6G",
        "outputId": "911ab3c8-9698-43df-f846-27714d9b52d6"
      },
      "source": [
        "from tensorflow.keras.optimizers import SGD, Adam, Adagrad, RMSprop\n",
        "import tensorflow.keras.backend as K\n",
        "\n",
        "dflist = []\n",
        "\n",
        "optimizers = ['SGD(learning_rate=0.01)',\n",
        "              'SGD(learning_rate=0.01, momentum=0.3)',\n",
        "              'SGD(learning_rate=0.01, momentum=0.3, nesterov=True)',  \n",
        "              'Adam(learning_rate=0.01)',\n",
        "              'Adagrad(learning_rate=0.01)',\n",
        "              'RMSprop(learning_rate=0.01)']\n",
        "\n",
        "for opt_name in optimizers:\n",
        "\n",
        "    K.clear_session()    \n",
        "    model = keras.models.Sequential([   \n",
        "    keras.layers.Dense(300, activation=\"relu\"),\n",
        "    keras.layers.Dense(100, activation=\"relu\"),\n",
        "    keras.layers.Dense(3, activation=\"sigmoid\")])    \n",
        "    model.compile(loss='sparse_categorical_crossentropy',\n",
        "                  optimizer=eval(opt_name),\n",
        "                  metrics=['accuracy'])\n",
        "    h = model.fit(X_train, y_train, batch_size=16, epochs=5, verbose=0)    \n",
        "    print(opt_name)\n",
        "    print(model.evaluate(X_test, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SGD(learning_rate=0.01)\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7278 - accuracy: 0.6883\n",
            "[0.7278109788894653, 0.6882591247558594]\n",
            "SGD(learning_rate=0.01, momentum=0.3)\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7238 - accuracy: 0.6943\n",
            "[0.7238156199455261, 0.6943320035934448]\n",
            "SGD(learning_rate=0.01, momentum=0.3, nesterov=True)\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7229 - accuracy: 0.6923\n",
            "[0.7229474782943726, 0.692307710647583]\n",
            "Adam(learning_rate=0.01)\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7414 - accuracy: 0.6862\n",
            "[0.7414220571517944, 0.6862348318099976]\n",
            "Adagrad(learning_rate=0.01)\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7251 - accuracy: 0.6862\n",
            "[0.7250977754592896, 0.6862348318099976]\n",
            "RMSprop(learning_rate=0.01)\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7563 - accuracy: 0.6964\n",
            "[0.7563157081604004, 0.6963562965393066]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kasm8Fcb8k8O",
        "outputId": "4e61ce6c-843f-4336-bece-831501e962d4"
      },
      "source": [
        "from tensorflow.keras.optimizers import SGD, Adam, Adagrad, RMSprop\n",
        "import tensorflow.keras.backend as K\n",
        "\n",
        "dflist = []\n",
        "\n",
        "batch_sizes = [16, 32, 64, 128,1000]\n",
        "\n",
        "for batch_size in batch_sizes:\n",
        "    K.clear_session()    \n",
        "    model = keras.models.Sequential([   \n",
        "    keras.layers.Dense(300, activation=\"relu\"),\n",
        "    keras.layers.Dense(100, activation=\"relu\"),\n",
        "    keras.layers.Dense(3, activation=\"sigmoid\")])    \n",
        "\n",
        "    model.compile(loss='sparse_categorical_crossentropy',\n",
        "                  optimizer='sgd',\n",
        "                  metrics=['accuracy'])\n",
        "    h = model.fit(X_train, y_train, batch_size=batch_size, verbose=0, epochs=10)\n",
        "    print(batch_size)\n",
        "    print(model.evaluate(X_test, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7237 - accuracy: 0.6943\n",
            "[0.7236694693565369, 0.6943320035934448]\n",
            "32\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.7226 - accuracy: 0.6923\n",
            "[0.7225515842437744, 0.692307710647583]\n",
            "64\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7227 - accuracy: 0.6862\n",
            "[0.7227292060852051, 0.6862348318099976]\n",
            "128\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7360 - accuracy: 0.6964\n",
            "[0.7359642386436462, 0.6963562965393066]\n",
            "1000\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7806 - accuracy: 0.6802\n",
            "[0.7806000113487244, 0.6801619529724121]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GJmikKiv-N4P",
        "outputId": "4775e7b9-8260-4796-b332-93b4e9cf3c57"
      },
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "model = keras.models.Sequential([   \n",
        "    keras.layers.Dense(300, activation=\"relu\"),\n",
        "    keras.layers.Dense(100, activation=\"relu\"),\n",
        "    keras.layers.Dense(3, activation=\"softmax\")\n",
        "])\n",
        "model.add(BatchNormalization())\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "              optimizer=\"sgd\",\n",
        "              metrics=[\"accuracy\"])\n",
        "history = model.fit(X_train, y_train, epochs=10)\n",
        "model.evaluate(X_test, y_test)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 4.7669 - accuracy: 0.5206\n",
            "Epoch 2/10\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 2.6494 - accuracy: 0.6390\n",
            "Epoch 3/10\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 2.6495 - accuracy: 0.6390\n",
            "Epoch 4/10\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 2.6495 - accuracy: 0.6390\n",
            "Epoch 5/10\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 2.6492 - accuracy: 0.6390\n",
            "Epoch 6/10\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 2.6494 - accuracy: 0.6390\n",
            "Epoch 7/10\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 2.6494 - accuracy: 0.6390\n",
            "Epoch 8/10\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 2.6494 - accuracy: 0.6390\n",
            "Epoch 9/10\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 2.6494 - accuracy: 0.6390\n",
            "Epoch 10/10\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 2.6495 - accuracy: 0.6390\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 2.7792 - accuracy: 0.6397\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2.7791640758514404, 0.6396760940551758]"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yXyeOZuC_MY0",
        "outputId": "8fffc7a9-f9c6-48db-9758-d086e900f7a7"
      },
      "source": [
        "dflist = []\n",
        "\n",
        "learning_rates = [.001,0.01, 0.05, 0.1, 0.5,1]\n",
        "\n",
        "for learning_rate in learning_rates:\n",
        "    K.clear_session()    \n",
        "    model = keras.models.Sequential([   \n",
        "    keras.layers.Dense(300, activation=\"relu\"),\n",
        "    keras.layers.Dense(100, activation=\"relu\"),\n",
        "    keras.layers.Dense(3, activation=\"sigmoid\")])    \n",
        "\n",
        "    model.compile(loss='sparse_categorical_crossentropy',\n",
        "                  optimizer=SGD(learning_rate=learning_rate),\n",
        "                  metrics=['accuracy'])\n",
        "    h = model.fit(X_train, y_train, batch_size=128, verbose=0, epochs=10)\n",
        "    print(learning_rate)\n",
        "    print(model.evaluate(X_test, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.001\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7951 - accuracy: 0.6700\n",
            "[0.7950705289840698, 0.670040488243103]\n",
            "0.01\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7320 - accuracy: 0.6964\n",
            "[0.7319791913032532, 0.6963562965393066]\n",
            "0.05\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.7244 - accuracy: 0.6862\n",
            "[0.7243712544441223, 0.6862348318099976]\n",
            "0.1\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7292 - accuracy: 0.6842\n",
            "[0.7292081713676453, 0.6842105388641357]\n",
            "0.5\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.7382 - accuracy: 0.6903\n",
            "[0.7382389307022095, 0.6902834177017212]\n",
            "1\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.7413 - accuracy: 0.6640\n",
            "[0.7413225173950195, 0.6639676094055176]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "odZtttwgAxXB",
        "outputId": "9c73e8f1-0cfd-4e56-c191-e864aa8d861b"
      },
      "source": [
        "dflist = []\n",
        "\n",
        "initializers = ['zeros', \n",
        "                'uniform', \n",
        "                'normal',\n",
        "                'he_normal', \n",
        "                'lecun_uniform']\n",
        "\n",
        "for initializers in initializers:\n",
        "    K.clear_session()    \n",
        "    model = keras.models.Sequential([   \n",
        "    keras.layers.Dense(300, activation=\"relu\",kernel_initializer=initializers),\n",
        "    keras.layers.Dense(100, activation=\"relu\"),\n",
        "    keras.layers.Dense(3, activation=\"sigmoid\")])    \n",
        "\n",
        "    model.compile(loss='sparse_categorical_crossentropy',\n",
        "                  optimizer=SGD(learning_rate=learning_rate),\n",
        "                  metrics=['accuracy'])\n",
        "    h = model.fit(X_train, y_train, batch_size=128, verbose=0, epochs=10)\n",
        "    print(initializers)\n",
        "    print(model.evaluate(X_test, y_test))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "zeros\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.8944 - accuracy: 0.6397\n",
            "[0.8944491744041443, 0.6396760940551758]\n",
            "uniform\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.7339 - accuracy: 0.6781\n",
            "[0.7339420914649963, 0.6781376600265503]\n",
            "normal\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7473 - accuracy: 0.6700\n",
            "[0.7473315596580505, 0.670040488243103]\n",
            "he_normal\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7908 - accuracy: 0.6700\n",
            "[0.7907854914665222, 0.670040488243103]\n",
            "lecun_uniform\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.7495 - accuracy: 0.6761\n",
            "[0.7495310306549072, 0.6761133670806885]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AaGQoTpu64sL"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "y_test_pred = model.predict(X_test)\n",
        "#confusion_matrix_valid = confusion_matrix(y_test, y_test_pred)\n",
        "#accuracy_score = accuracy_score(y_test, y_test_pred)\n",
        "#print(confusion_matrix_valid, accuracy_score) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-2liQR819qY0"
      },
      "source": [
        "### **ADAboost**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PXHe9A_KmB0w",
        "outputId": "cdb2ca6b-0a42-47f0-9e6d-d57cdd569e17"
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "\n",
        "ada_clf = AdaBoostClassifier(\n",
        "    DecisionTreeClassifier(max_depth=1), n_estimators=200,\n",
        "    algorithm=\"SAMME.R\", learning_rate=0.5, random_state=42)\n",
        "ada_clf.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AdaBoostClassifier(algorithm='SAMME.R',\n",
              "                   base_estimator=DecisionTreeClassifier(ccp_alpha=0.0,\n",
              "                                                         class_weight=None,\n",
              "                                                         criterion='gini',\n",
              "                                                         max_depth=1,\n",
              "                                                         max_features=None,\n",
              "                                                         max_leaf_nodes=None,\n",
              "                                                         min_impurity_decrease=0.0,\n",
              "                                                         min_impurity_split=None,\n",
              "                                                         min_samples_leaf=1,\n",
              "                                                         min_samples_split=2,\n",
              "                                                         min_weight_fraction_leaf=0.0,\n",
              "                                                         presort='deprecated',\n",
              "                                                         random_state=None,\n",
              "                                                         splitter='best'),\n",
              "                   learning_rate=0.5, n_estimators=200, random_state=42)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MKdUVU47pwns",
        "outputId": "f6117f9f-6481-4bde-cc5d-435129fe5439"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "y_train_pred = ada_clf.predict(X_train)\n",
        "y_test_pred = ada_clf.predict(X_test)\n",
        "\n",
        "print(f'Train score {accuracy_score(y_train_pred,y_train)}')\n",
        "print(f'Test score {accuracy_score(y_test_pred,y_test)}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train score 0.6895861982747844\n",
            "Test score 0.6842105263157895\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tsdTE-utpb3D",
        "outputId": "416d9ab0-1085-429b-af6d-0a8662bbef79"
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "\n",
        "ada_clf = AdaBoostClassifier(\n",
        "    DecisionTreeClassifier(max_depth=1), n_estimators=50,\n",
        "    algorithm=\"SAMME.R\", learning_rate=1, random_state=42)\n",
        "ada_clf.fit(X_train, y_train)\n",
        "y_train_pred = ada_clf.predict(X_train)\n",
        "y_test_pred = ada_clf.predict(X_test)\n",
        "\n",
        "print(f'Train score {accuracy_score(y_train_pred,y_train)}')\n",
        "print(f'Test score {accuracy_score(y_test_pred,y_test)}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train score 0.6848356044505564\n",
            "Test score 0.680161943319838\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-RVi9kMap0TE",
        "outputId": "1ba779d5-c44a-4a2a-9922-53619adf4405"
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "\n",
        "ada_clf = AdaBoostClassifier(\n",
        "    DecisionTreeClassifier(max_depth=1), n_estimators=100,\n",
        "    algorithm=\"SAMME.R\", learning_rate=5, random_state=42)\n",
        "ada_clf.fit(X_train, y_train)\n",
        "y_train_pred = ada_clf.predict(X_train)\n",
        "y_test_pred = ada_clf.predict(X_test)\n",
        "\n",
        "print(f'Train score {accuracy_score(y_train_pred,y_train)}')\n",
        "print(f'Test score {accuracy_score(y_test_pred,y_test)}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train score 0.23015376922115263\n",
            "Test score 0.22064777327935223\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cs9sH_Hep3UG",
        "outputId": "3ad13d89-fe57-4176-8176-8bcaf72f6929"
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "\n",
        "ada_clf = AdaBoostClassifier(\n",
        "    DecisionTreeClassifier(max_depth=1), n_estimators=50,\n",
        "    algorithm=\"SAMME.R\", learning_rate=.01, random_state=42)\n",
        "ada_clf.fit(X_train, y_train)\n",
        "y_train_pred = ada_clf.predict(X_train)\n",
        "y_test_pred = ada_clf.predict(X_test)\n",
        "\n",
        "print(f'Train score {accuracy_score(y_train_pred,y_train)}')\n",
        "print(f'Test score {accuracy_score(y_test_pred,y_test)}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train score 0.6389548693586699\n",
            "Test score 0.6396761133603239\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K7Cj_CHwp6M5",
        "outputId": "b73e7940-a518-4944-9144-27aeb89eefcc"
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "\n",
        "ada_clf = AdaBoostClassifier(\n",
        "    DecisionTreeClassifier(max_depth=1), n_estimators=100,\n",
        "    algorithm=\"SAMME.R\", learning_rate=1, random_state=42)\n",
        "ada_clf.fit(X_train, y_train)\n",
        "y_train_pred = ada_clf.predict(X_train)\n",
        "y_test_pred = ada_clf.predict(X_test)\n",
        "\n",
        "print(f'Train score {accuracy_score(y_train_pred,y_train)}')\n",
        "print(f'Test score {accuracy_score(y_test_pred,y_test)}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train score 0.6863357919739967\n",
            "Test score 0.6902834008097166\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XkbpbNMt9v95"
      },
      "source": [
        "### **SVM**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KfR9lGHSsm1t",
        "outputId": "1fe70949-d20f-47f4-db60-5c18bf8379ef"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV \n",
        "from sklearn.svm import SVC\n",
        "\n",
        "\n",
        "param_test1 = {\n",
        "  'gamma':(0.01,0.05,0.1),\n",
        "   'C':(.001,.01,.1,1,1000) \n",
        "}\n",
        "gsearch1 = GridSearchCV(estimator = SVC(class_weight='balanced'), \n",
        "param_grid = param_test1,scoring='accuracy', n_jobs=10,iid=False, cv=5)\n",
        "gsearch1.fit(X_train,y_train)\n",
        "gsearch1.cv_results_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:823: FutureWarning: The parameter 'iid' is deprecated in 0.22 and will be removed in 0.24.\n",
            "  \"removed in 0.24.\", FutureWarning\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'mean_fit_time': array([ 24.80978155,  38.50335512,  41.38976321,  34.0767252 ,\n",
              "         34.91131563,  38.54928074,  28.52338204,  29.18693199,\n",
              "         30.53013282,  26.03620787,  27.33471274,  27.20499449,\n",
              "        117.56066651, 127.19807487,  54.53532734]),\n",
              " 'mean_score_time': array([3.33666573, 4.7393827 , 4.77883787, 4.45925193, 4.41492352,\n",
              "        4.61119604, 3.8521596 , 3.90343318, 3.92521353, 3.62804551,\n",
              "        3.64599371, 3.71699567, 3.26683993, 2.52766156, 1.16684132]),\n",
              " 'mean_test_score': array([0.15140369, 0.13089134, 0.13089134, 0.62082989, 0.54982403,\n",
              "        0.49744176, 0.5974538 , 0.55095098, 0.50831864, 0.58320364,\n",
              "        0.49482411, 0.45944567, 0.42331997, 0.38256246, 0.38781066]),\n",
              " 'param_C': masked_array(data=[0.001, 0.001, 0.001, 0.01, 0.01, 0.01, 0.1, 0.1, 0.1,\n",
              "                    1, 1, 1, 1000, 1000, 1000],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'param_gamma': masked_array(data=[0.01, 0.05, 0.1, 0.01, 0.05, 0.1, 0.01, 0.05, 0.1,\n",
              "                    0.01, 0.05, 0.1, 0.01, 0.05, 0.1],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'params': [{'C': 0.001, 'gamma': 0.01},\n",
              "  {'C': 0.001, 'gamma': 0.05},\n",
              "  {'C': 0.001, 'gamma': 0.1},\n",
              "  {'C': 0.01, 'gamma': 0.01},\n",
              "  {'C': 0.01, 'gamma': 0.05},\n",
              "  {'C': 0.01, 'gamma': 0.1},\n",
              "  {'C': 0.1, 'gamma': 0.01},\n",
              "  {'C': 0.1, 'gamma': 0.05},\n",
              "  {'C': 0.1, 'gamma': 0.1},\n",
              "  {'C': 1, 'gamma': 0.01},\n",
              "  {'C': 1, 'gamma': 0.05},\n",
              "  {'C': 1, 'gamma': 0.1},\n",
              "  {'C': 1000, 'gamma': 0.01},\n",
              "  {'C': 1000, 'gamma': 0.05},\n",
              "  {'C': 1000, 'gamma': 0.1}],\n",
              " 'rank_test_score': array([13, 14, 14,  1,  5,  7,  2,  4,  6,  3,  8,  9, 10, 12, 11],\n",
              "       dtype=int32),\n",
              " 'split0_test_score': array([0.134375, 0.130625, 0.130625, 0.708125, 0.66625 , 0.614375,\n",
              "        0.68625 , 0.651875, 0.638125, 0.686875, 0.638125, 0.619375,\n",
              "        0.588125, 0.57    , 0.55875 ]),\n",
              " 'split1_test_score': array([0.130625, 0.130625, 0.130625, 0.651875, 0.5825  , 0.555   ,\n",
              "        0.6275  , 0.585   , 0.550625, 0.605625, 0.495625, 0.439375,\n",
              "        0.3725  , 0.29625 , 0.306875]),\n",
              " 'split2_test_score': array([0.13125 , 0.13125 , 0.13125 , 0.6775  , 0.61    , 0.520625,\n",
              "        0.68125 , 0.61375 , 0.53375 , 0.633125, 0.46625 , 0.41125 ,\n",
              "        0.3175  , 0.26875 , 0.275   ]),\n",
              " 'split3_test_score': array([0.13125 , 0.13125 , 0.13125 , 0.4275  , 0.298125, 0.263125,\n",
              "        0.361875, 0.29625 , 0.27    , 0.36125 , 0.28125 , 0.261875,\n",
              "        0.27875 , 0.278125, 0.313125]),\n",
              " 'split4_test_score': array([0.22951845, 0.13070669, 0.13070669, 0.63914947, 0.59224515,\n",
              "        0.5340838 , 0.630394  , 0.60787992, 0.54909318, 0.62914321,\n",
              "        0.59287054, 0.56535335, 0.55972483, 0.4996873 , 0.48530331]),\n",
              " 'std_fit_time': array([0.50939496, 6.93260139, 0.27153551, 0.65560387, 0.65876903,\n",
              "        0.72575435, 0.78778008, 0.98713044, 0.71429117, 1.35792357,\n",
              "        0.81083165, 0.53600428, 5.88633644, 4.39204828, 4.89245173]),\n",
              " 'std_score_time': array([0.78514559, 0.10008056, 0.01040318, 0.036032  , 0.10491129,\n",
              "        0.07064608, 0.062885  , 0.07898423, 0.10100516, 0.07069221,\n",
              "        0.06630833, 0.04983167, 0.0820618 , 0.40974998, 0.36580357]),\n",
              " 'std_test_score': array([0.03907938, 0.00029436, 0.00029436, 0.09950657, 0.12914784,\n",
              "        0.12146669, 0.12032603, 0.12915278, 0.12469532, 0.11411965,\n",
              "        0.12375724, 0.12534245, 0.12684478, 0.12661861, 0.11276511])}"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nHFOD4_1ugB2",
        "outputId": "439717c4-8313-41b3-e0fa-51391f87ae75"
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "final = SVC(C=0.01, break_ties=False, cache_size=200, class_weight='balanced',\n",
        "    coef0=0.0, decision_function_shape='ovr', degree=3, gamma=0.01,\n",
        "    kernel='rbf', max_iter=-1, probability=True, random_state=None,\n",
        "    shrinking=True, tol=0.001, verbose=False)\n",
        "final.fit(X_train, y_train)\n",
        "y_train_pred= final.predict(X_train)\n",
        "y_test_pred = final.predict(X_test)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "confusion_matrix_valid = confusion_matrix(y_test, y_test_pred)\n",
        "print(confusion_matrix_valid) \n",
        "print(f'Train score {accuracy_score(y_train_pred,y_train)}')\n",
        "print(f'Test score {accuracy_score(y_test_pred,y_test)}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[241  50  25]\n",
            " [ 54  30  25]\n",
            " [  7  18  44]]\n",
            "Train score 0.6314539317414677\n",
            "Test score 0.6376518218623481\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vOHJsk9Qq9a_",
        "outputId": "8ef708f2-f6fb-423c-f7e1-c38b697eb3a8"
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "final = SVC(C=0.001, break_ties=False, cache_size=200, class_weight='balanced',\n",
        "    coef0=0.0, decision_function_shape='ovr', degree=3, gamma=0.01,\n",
        "    kernel='rbf', max_iter=-1, probability=True, random_state=None,\n",
        "    shrinking=True, tol=0.001, verbose=False)\n",
        "final.fit(X_train, y_train)\n",
        "y_train_pred= final.predict(X_train)\n",
        "y_test_pred = final.predict(X_test)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "confusion_matrix_valid = confusion_matrix(y_test, y_test_pred)\n",
        "print(confusion_matrix_valid) \n",
        "print(f'Train score {accuracy_score(y_train_pred,y_train)}')\n",
        "print(f'Test score {accuracy_score(y_test_pred,y_test)}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[157   0 159]\n",
            " [ 22   0  87]\n",
            " [  3   0  66]]\n",
            "Train score 0.45405675709463683\n",
            "Test score 0.451417004048583\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q336nxAcskat",
        "outputId": "408c95ad-d554-4ce9-9883-c1fb54951760"
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "final = SVC(C=0.001, break_ties=False, cache_size=200, class_weight='balanced',\n",
        "    coef0=0.0, decision_function_shape='ovr', degree=3, gamma=0.1,\n",
        "    kernel='rbf', max_iter=-1, probability=True, random_state=None,\n",
        "    shrinking=True, tol=0.001, verbose=False)\n",
        "final.fit(X_train, y_train)\n",
        "y_train_pred= final.predict(X_train)\n",
        "y_test_pred = final.predict(X_test)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "confusion_matrix_valid = confusion_matrix(y_test, y_test_pred)\n",
        "print(confusion_matrix_valid) \n",
        "print(f'Train score {accuracy_score(y_train_pred,y_train)}')\n",
        "print(f'Test score {accuracy_score(y_test_pred,y_test)}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[  0   0 316]\n",
            " [  0   0 109]\n",
            " [  0   0  69]]\n",
            "Train score 0.13089136142017752\n",
            "Test score 0.1396761133603239\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D4BOtb9Csefw",
        "outputId": "a6177eb1-08de-4d78-d453-c42c2675f8fb"
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "final = SVC(C=0.1, break_ties=False, cache_size=200, class_weight='balanced',\n",
        "    coef0=0.0, decision_function_shape='ovr', degree=3, gamma=0.01,\n",
        "    kernel='rbf', max_iter=-1, probability=True, random_state=None,\n",
        "    shrinking=True, tol=0.001, verbose=False)\n",
        "final.fit(X_train, y_train)\n",
        "y_train_pred= final.predict(X_train)\n",
        "y_test_pred = final.predict(X_test)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "confusion_matrix_valid = confusion_matrix(y_test, y_test_pred)\n",
        "print(confusion_matrix_valid) \n",
        "print(f'Train score {accuracy_score(y_train_pred,y_train)}')\n",
        "print(f'Test score {accuracy_score(y_test_pred,y_test)}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[222  70  24]\n",
            " [ 41  41  27]\n",
            " [  5  19  45]]\n",
            "Train score 0.6300787598449806\n",
            "Test score 0.6234817813765182\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ThOjguCesosY",
        "outputId": "1d0e0405-0927-447c-e750-27be69d7f8a8"
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "final = SVC(C=0.1, break_ties=False, cache_size=200, class_weight='balanced',\n",
        "    coef0=0.0, decision_function_shape='ovr', degree=3, gamma=0.1,\n",
        "    kernel='rbf', max_iter=-1, probability=True, random_state=None,\n",
        "    shrinking=True, tol=0.001, verbose=False)\n",
        "final.fit(X_train, y_train)\n",
        "y_train_pred= final.predict(X_train)\n",
        "y_test_pred = final.predict(X_test)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "confusion_matrix_valid = confusion_matrix(y_test, y_test_pred)\n",
        "print(confusion_matrix_valid) \n",
        "print(f'Train score {accuracy_score(y_train_pred,y_train)}')\n",
        "print(f'Test score {accuracy_score(y_test_pred,y_test)}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[192  79  45]\n",
            " [ 32  37  40]\n",
            " [  3  18  48]]\n",
            "Train score 0.5913239154894362\n",
            "Test score 0.5607287449392713\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SsuXDxBIsvpv",
        "outputId": "e0df187b-418d-4700-9b02-37f78ba6e48f"
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "final = SVC(C=10, break_ties=False, cache_size=200, class_weight='balanced',\n",
        "    coef0=0.0, decision_function_shape='ovr', degree=3, gamma=0.1,\n",
        "    kernel='rbf', max_iter=-1, probability=True, random_state=None,\n",
        "    shrinking=True, tol=0.001, verbose=False)\n",
        "final.fit(X_train, y_train)\n",
        "y_train_pred= final.predict(X_train)\n",
        "y_test_pred = final.predict(X_test)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "confusion_matrix_valid = confusion_matrix(y_test, y_test_pred)\n",
        "print(confusion_matrix_valid) \n",
        "print(f'Train score {accuracy_score(y_train_pred,y_train)}')\n",
        "print(f'Test score {accuracy_score(y_test_pred,y_test)}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[199  93  24]\n",
            " [ 44  43  22]\n",
            " [ 14  23  32]]\n",
            "Train score 0.7985998249781223\n",
            "Test score 0.5546558704453441\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6oakV_clu4WP"
      },
      "source": [
        "https://github.com/ageron/handson-ml2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PGZ3BpIovVKe",
        "outputId": "4511e337-a483-4afa-d4d4-807357a5722c"
      },
      "source": [
        "## Polynomial Kernel\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "poly100_kernel_svm_clf = Pipeline([\n",
        "        (\"svm_clf\", SVC(kernel=\"poly\", degree=2, coef0=100, C=5,cache_size=200000))\n",
        "    ])\n",
        "poly100_kernel_svm_clf.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('svm_clf',\n",
              "                 SVC(C=5, break_ties=False, cache_size=200000,\n",
              "                     class_weight=None, coef0=100,\n",
              "                     decision_function_shape='ovr', degree=2, gamma='scale',\n",
              "                     kernel='poly', max_iter=-1, probability=False,\n",
              "                     random_state=None, shrinking=True, tol=0.001,\n",
              "                     verbose=False))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wawftky7wdkI",
        "outputId": "acb0311c-b280-4956-b757-c40543114eae"
      },
      "source": [
        "\n",
        "y_train_pred= poly100_kernel_svm_clf.predict(X_train)\n",
        "y_test_pred = poly100_kernel_svm_clf.predict(X_test)\n",
        "confusion_matrix_valid = confusion_matrix(y_test, y_test_pred)\n",
        "\n",
        "accuracy_score = accuracy_score(y_test, y_test_pred)\n",
        "print(confusion_matrix_valid, accuracy_score) \n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "print(f'Train score {accuracy_score(y_train_pred,y_train)}')\n",
        "print(f'Test score {accuracy_score(y_test_pred,y_test)}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[303   4   9]\n",
            " [ 93   6  10]\n",
            " [ 31   7  31]] 0.6882591093117408\n",
            "Train score 0.7022127765970746\n",
            "Test score 0.6882591093117408\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JOBI-ViN96HV"
      },
      "source": [
        "### **kNN**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SWKWaejCIuaL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c06a365-81c2-4be7-85f2-188f59a3038b"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import GridSearchCV \n",
        "\n",
        "leaf_size = list(range(1,50,2))\n",
        "n_neighbors = list(range(180,300,20))\n",
        "\n",
        "param_test1 = {\n",
        "  'leaf_size':(1,5,101,5,20,25,30,35,40,45,50,100),\n",
        "   'n_neighbors':(180,200,230,250,300,400,500) \n",
        "}\n",
        "\n",
        "\n",
        "gsearch1 = GridSearchCV(estimator = KNeighborsClassifier(),param_grid = param_test1,scoring='accuracy', n_jobs=10,iid=False, cv=5)\n",
        "gsearch1.fit(X_train,y_train)\n",
        "gsearch1.cv_results_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:823: FutureWarning: The parameter 'iid' is deprecated in 0.22 and will be removed in 0.24.\n",
            "  \"removed in 0.24.\", FutureWarning\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'mean_fit_time': array([0.17990704, 0.38943577, 0.33240843, 0.33824224, 0.34046884,\n",
              "        0.33506761, 0.33721657, 0.26007996, 0.27559934, 0.24712958,\n",
              "        0.27554007, 0.27173429, 0.2638351 , 0.26179109, 0.16667676,\n",
              "        0.17440505, 0.18087502, 0.17912402, 0.17319751, 0.18051724,\n",
              "        0.17921357, 0.29420514, 0.26921439, 0.27709026, 0.27196169,\n",
              "        0.26145372, 0.27209759, 0.26643815, 0.22121429, 0.23018327,\n",
              "        0.22743711, 0.22676864, 0.23355651, 0.23948712, 0.22753596,\n",
              "        0.20973258, 0.21833892, 0.22008967, 0.21023178, 0.21381407,\n",
              "        0.21481028, 0.21239653, 0.2035965 , 0.21727347, 0.21146536,\n",
              "        0.2103816 , 0.21983576, 0.21390524, 0.21387224, 0.21978769,\n",
              "        0.21436672, 0.21405454, 0.21367245, 0.2126287 , 0.21528368,\n",
              "        0.21903071, 0.21374454, 0.22065568, 0.21173887, 0.21493626,\n",
              "        0.21034555, 0.21692624, 0.20491471, 0.2010344 , 0.21110926,\n",
              "        0.21156693, 0.21076884, 0.21526623, 0.20695424, 0.225734  ,\n",
              "        0.19657764, 0.19598441, 0.20094504, 0.20233531, 0.19263878,\n",
              "        0.19106832, 0.19132786, 0.16961093, 0.18405828, 0.17276468,\n",
              "        0.17768002, 0.17927585, 0.17070394, 0.1850934 ]),\n",
              " 'mean_score_time': array([15.16038647, 29.79558315, 31.16779428, 32.27447805, 34.1786027 ,\n",
              "        37.70891361, 40.71099253, 14.67845235, 15.18324137, 15.93211284,\n",
              "        16.36396217, 16.87088118, 18.32046771, 19.5925611 ,  5.39475431,\n",
              "         5.68494754,  5.75122452,  6.03272624,  6.3045176 ,  6.71770301,\n",
              "         6.99176774, 15.04576349, 15.28789859, 15.89634352, 16.17246709,\n",
              "        16.98805208, 18.34605517, 19.77839422,  7.66379142,  8.03881488,\n",
              "         8.43002014,  8.66305552,  9.02257214,  9.92247496, 10.5960104 ,\n",
              "         6.6429862 ,  6.82595701,  7.00846663,  7.05440598,  7.5213222 ,\n",
              "         8.1112371 ,  8.63545895,  6.65371923,  6.83223071,  7.04829078,\n",
              "         7.17814779,  7.48713603,  8.10724587,  8.68990936,  6.70404186,\n",
              "         6.87899098,  7.09094992,  7.19695883,  7.59789267,  8.20126109,\n",
              "         8.68435764,  6.71262007,  6.8131784 ,  7.04633727,  7.15686393,\n",
              "         7.5348258 ,  8.01910124,  8.74230013,  6.66452246,  6.80733151,\n",
              "         7.02410517,  7.17083592,  7.43526192,  8.03360162,  8.70734587,\n",
              "         6.0218277 ,  6.14623251,  6.30866094,  6.46281729,  6.69799266,\n",
              "         7.21656833,  7.73873372,  5.64486718,  5.73518262,  5.90588412,\n",
              "         5.96987491,  6.22390585,  6.32083874,  4.66196799]),\n",
              " 'mean_test_score': array([0.6630806 , 0.66495552, 0.66520552, 0.66408044, 0.66545552,\n",
              "        0.66983052, 0.66770536, 0.6630806 , 0.66495552, 0.66520552,\n",
              "        0.66408044, 0.66545552, 0.66983052, 0.66770536, 0.6630806 ,\n",
              "        0.66495552, 0.66520552, 0.66408044, 0.66545552, 0.66983052,\n",
              "        0.66770536, 0.6630806 , 0.66495552, 0.66520552, 0.66408044,\n",
              "        0.66545552, 0.66983052, 0.66770536, 0.6630806 , 0.66495552,\n",
              "        0.66520552, 0.66408044, 0.66545552, 0.66983052, 0.66770536,\n",
              "        0.6630806 , 0.66495552, 0.66520552, 0.66408044, 0.66545552,\n",
              "        0.66983052, 0.66770536, 0.6630806 , 0.66495552, 0.66520552,\n",
              "        0.66408044, 0.66545552, 0.66983052, 0.66770536, 0.6630806 ,\n",
              "        0.66495552, 0.66520552, 0.66408044, 0.66545552, 0.66983052,\n",
              "        0.66770536, 0.6630806 , 0.66495552, 0.66520552, 0.66408044,\n",
              "        0.66545552, 0.66983052, 0.66770536, 0.6630806 , 0.66495552,\n",
              "        0.66520552, 0.66408044, 0.66545552, 0.66983052, 0.66770536,\n",
              "        0.6630806 , 0.66495552, 0.66520552, 0.66408044, 0.66545552,\n",
              "        0.66983052, 0.66770536, 0.6630806 , 0.66495552, 0.66520552,\n",
              "        0.66408044, 0.66545552, 0.66983052, 0.66770536]),\n",
              " 'param_leaf_size': masked_array(data=[1, 1, 1, 1, 1, 1, 1, 5, 5, 5, 5, 5, 5, 5, 101, 101,\n",
              "                    101, 101, 101, 101, 101, 5, 5, 5, 5, 5, 5, 5, 20, 20,\n",
              "                    20, 20, 20, 20, 20, 25, 25, 25, 25, 25, 25, 25, 30, 30,\n",
              "                    30, 30, 30, 30, 30, 35, 35, 35, 35, 35, 35, 35, 40, 40,\n",
              "                    40, 40, 40, 40, 40, 45, 45, 45, 45, 45, 45, 45, 50, 50,\n",
              "                    50, 50, 50, 50, 50, 100, 100, 100, 100, 100, 100, 100],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'param_n_neighbors': masked_array(data=[180, 200, 230, 250, 300, 400, 500, 180, 200, 230, 250,\n",
              "                    300, 400, 500, 180, 200, 230, 250, 300, 400, 500, 180,\n",
              "                    200, 230, 250, 300, 400, 500, 180, 200, 230, 250, 300,\n",
              "                    400, 500, 180, 200, 230, 250, 300, 400, 500, 180, 200,\n",
              "                    230, 250, 300, 400, 500, 180, 200, 230, 250, 300, 400,\n",
              "                    500, 180, 200, 230, 250, 300, 400, 500, 180, 200, 230,\n",
              "                    250, 300, 400, 500, 180, 200, 230, 250, 300, 400, 500,\n",
              "                    180, 200, 230, 250, 300, 400, 500],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'params': [{'leaf_size': 1, 'n_neighbors': 180},\n",
              "  {'leaf_size': 1, 'n_neighbors': 200},\n",
              "  {'leaf_size': 1, 'n_neighbors': 230},\n",
              "  {'leaf_size': 1, 'n_neighbors': 250},\n",
              "  {'leaf_size': 1, 'n_neighbors': 300},\n",
              "  {'leaf_size': 1, 'n_neighbors': 400},\n",
              "  {'leaf_size': 1, 'n_neighbors': 500},\n",
              "  {'leaf_size': 5, 'n_neighbors': 180},\n",
              "  {'leaf_size': 5, 'n_neighbors': 200},\n",
              "  {'leaf_size': 5, 'n_neighbors': 230},\n",
              "  {'leaf_size': 5, 'n_neighbors': 250},\n",
              "  {'leaf_size': 5, 'n_neighbors': 300},\n",
              "  {'leaf_size': 5, 'n_neighbors': 400},\n",
              "  {'leaf_size': 5, 'n_neighbors': 500},\n",
              "  {'leaf_size': 101, 'n_neighbors': 180},\n",
              "  {'leaf_size': 101, 'n_neighbors': 200},\n",
              "  {'leaf_size': 101, 'n_neighbors': 230},\n",
              "  {'leaf_size': 101, 'n_neighbors': 250},\n",
              "  {'leaf_size': 101, 'n_neighbors': 300},\n",
              "  {'leaf_size': 101, 'n_neighbors': 400},\n",
              "  {'leaf_size': 101, 'n_neighbors': 500},\n",
              "  {'leaf_size': 5, 'n_neighbors': 180},\n",
              "  {'leaf_size': 5, 'n_neighbors': 200},\n",
              "  {'leaf_size': 5, 'n_neighbors': 230},\n",
              "  {'leaf_size': 5, 'n_neighbors': 250},\n",
              "  {'leaf_size': 5, 'n_neighbors': 300},\n",
              "  {'leaf_size': 5, 'n_neighbors': 400},\n",
              "  {'leaf_size': 5, 'n_neighbors': 500},\n",
              "  {'leaf_size': 20, 'n_neighbors': 180},\n",
              "  {'leaf_size': 20, 'n_neighbors': 200},\n",
              "  {'leaf_size': 20, 'n_neighbors': 230},\n",
              "  {'leaf_size': 20, 'n_neighbors': 250},\n",
              "  {'leaf_size': 20, 'n_neighbors': 300},\n",
              "  {'leaf_size': 20, 'n_neighbors': 400},\n",
              "  {'leaf_size': 20, 'n_neighbors': 500},\n",
              "  {'leaf_size': 25, 'n_neighbors': 180},\n",
              "  {'leaf_size': 25, 'n_neighbors': 200},\n",
              "  {'leaf_size': 25, 'n_neighbors': 230},\n",
              "  {'leaf_size': 25, 'n_neighbors': 250},\n",
              "  {'leaf_size': 25, 'n_neighbors': 300},\n",
              "  {'leaf_size': 25, 'n_neighbors': 400},\n",
              "  {'leaf_size': 25, 'n_neighbors': 500},\n",
              "  {'leaf_size': 30, 'n_neighbors': 180},\n",
              "  {'leaf_size': 30, 'n_neighbors': 200},\n",
              "  {'leaf_size': 30, 'n_neighbors': 230},\n",
              "  {'leaf_size': 30, 'n_neighbors': 250},\n",
              "  {'leaf_size': 30, 'n_neighbors': 300},\n",
              "  {'leaf_size': 30, 'n_neighbors': 400},\n",
              "  {'leaf_size': 30, 'n_neighbors': 500},\n",
              "  {'leaf_size': 35, 'n_neighbors': 180},\n",
              "  {'leaf_size': 35, 'n_neighbors': 200},\n",
              "  {'leaf_size': 35, 'n_neighbors': 230},\n",
              "  {'leaf_size': 35, 'n_neighbors': 250},\n",
              "  {'leaf_size': 35, 'n_neighbors': 300},\n",
              "  {'leaf_size': 35, 'n_neighbors': 400},\n",
              "  {'leaf_size': 35, 'n_neighbors': 500},\n",
              "  {'leaf_size': 40, 'n_neighbors': 180},\n",
              "  {'leaf_size': 40, 'n_neighbors': 200},\n",
              "  {'leaf_size': 40, 'n_neighbors': 230},\n",
              "  {'leaf_size': 40, 'n_neighbors': 250},\n",
              "  {'leaf_size': 40, 'n_neighbors': 300},\n",
              "  {'leaf_size': 40, 'n_neighbors': 400},\n",
              "  {'leaf_size': 40, 'n_neighbors': 500},\n",
              "  {'leaf_size': 45, 'n_neighbors': 180},\n",
              "  {'leaf_size': 45, 'n_neighbors': 200},\n",
              "  {'leaf_size': 45, 'n_neighbors': 230},\n",
              "  {'leaf_size': 45, 'n_neighbors': 250},\n",
              "  {'leaf_size': 45, 'n_neighbors': 300},\n",
              "  {'leaf_size': 45, 'n_neighbors': 400},\n",
              "  {'leaf_size': 45, 'n_neighbors': 500},\n",
              "  {'leaf_size': 50, 'n_neighbors': 180},\n",
              "  {'leaf_size': 50, 'n_neighbors': 200},\n",
              "  {'leaf_size': 50, 'n_neighbors': 230},\n",
              "  {'leaf_size': 50, 'n_neighbors': 250},\n",
              "  {'leaf_size': 50, 'n_neighbors': 300},\n",
              "  {'leaf_size': 50, 'n_neighbors': 400},\n",
              "  {'leaf_size': 50, 'n_neighbors': 500},\n",
              "  {'leaf_size': 100, 'n_neighbors': 180},\n",
              "  {'leaf_size': 100, 'n_neighbors': 200},\n",
              "  {'leaf_size': 100, 'n_neighbors': 230},\n",
              "  {'leaf_size': 100, 'n_neighbors': 250},\n",
              "  {'leaf_size': 100, 'n_neighbors': 300},\n",
              "  {'leaf_size': 100, 'n_neighbors': 400},\n",
              "  {'leaf_size': 100, 'n_neighbors': 500}],\n",
              " 'rank_test_score': array([73, 49, 37, 61, 25,  1, 13, 73, 49, 37, 61, 25,  1, 13, 73, 49, 37,\n",
              "        61, 25,  1, 13, 73, 49, 37, 61, 25,  1, 13, 73, 49, 37, 61, 25,  1,\n",
              "        13, 73, 49, 37, 61, 25,  1, 13, 73, 49, 37, 61, 25,  1, 13, 73, 49,\n",
              "        37, 61, 25,  1, 13, 73, 49, 37, 61, 25,  1, 13, 73, 49, 37, 61, 25,\n",
              "         1, 13, 73, 49, 37, 61, 25,  1, 13, 73, 49, 37, 61, 25,  1, 13],\n",
              "       dtype=int32),\n",
              " 'split0_test_score': array([0.653125, 0.655   , 0.651875, 0.65125 , 0.651875, 0.651875,\n",
              "        0.65    , 0.653125, 0.655   , 0.651875, 0.65125 , 0.651875,\n",
              "        0.651875, 0.65    , 0.653125, 0.655   , 0.651875, 0.65125 ,\n",
              "        0.651875, 0.651875, 0.65    , 0.653125, 0.655   , 0.651875,\n",
              "        0.65125 , 0.651875, 0.651875, 0.65    , 0.653125, 0.655   ,\n",
              "        0.651875, 0.65125 , 0.651875, 0.651875, 0.65    , 0.653125,\n",
              "        0.655   , 0.651875, 0.65125 , 0.651875, 0.651875, 0.65    ,\n",
              "        0.653125, 0.655   , 0.651875, 0.65125 , 0.651875, 0.651875,\n",
              "        0.65    , 0.653125, 0.655   , 0.651875, 0.65125 , 0.651875,\n",
              "        0.651875, 0.65    , 0.653125, 0.655   , 0.651875, 0.65125 ,\n",
              "        0.651875, 0.651875, 0.65    , 0.653125, 0.655   , 0.651875,\n",
              "        0.65125 , 0.651875, 0.651875, 0.65    , 0.653125, 0.655   ,\n",
              "        0.651875, 0.65125 , 0.651875, 0.651875, 0.65    , 0.653125,\n",
              "        0.655   , 0.651875, 0.65125 , 0.651875, 0.651875, 0.65    ]),\n",
              " 'split1_test_score': array([0.696875, 0.6975  , 0.700625, 0.69875 , 0.69375 , 0.700625,\n",
              "        0.695625, 0.696875, 0.6975  , 0.700625, 0.69875 , 0.69375 ,\n",
              "        0.700625, 0.695625, 0.696875, 0.6975  , 0.700625, 0.69875 ,\n",
              "        0.69375 , 0.700625, 0.695625, 0.696875, 0.6975  , 0.700625,\n",
              "        0.69875 , 0.69375 , 0.700625, 0.695625, 0.696875, 0.6975  ,\n",
              "        0.700625, 0.69875 , 0.69375 , 0.700625, 0.695625, 0.696875,\n",
              "        0.6975  , 0.700625, 0.69875 , 0.69375 , 0.700625, 0.695625,\n",
              "        0.696875, 0.6975  , 0.700625, 0.69875 , 0.69375 , 0.700625,\n",
              "        0.695625, 0.696875, 0.6975  , 0.700625, 0.69875 , 0.69375 ,\n",
              "        0.700625, 0.695625, 0.696875, 0.6975  , 0.700625, 0.69875 ,\n",
              "        0.69375 , 0.700625, 0.695625, 0.696875, 0.6975  , 0.700625,\n",
              "        0.69875 , 0.69375 , 0.700625, 0.695625, 0.696875, 0.6975  ,\n",
              "        0.700625, 0.69875 , 0.69375 , 0.700625, 0.695625, 0.696875,\n",
              "        0.6975  , 0.700625, 0.69875 , 0.69375 , 0.700625, 0.695625]),\n",
              " 'split2_test_score': array([0.698125, 0.7025  , 0.700625, 0.7     , 0.704375, 0.708125,\n",
              "        0.704375, 0.698125, 0.7025  , 0.700625, 0.7     , 0.704375,\n",
              "        0.708125, 0.704375, 0.698125, 0.7025  , 0.700625, 0.7     ,\n",
              "        0.704375, 0.708125, 0.704375, 0.698125, 0.7025  , 0.700625,\n",
              "        0.7     , 0.704375, 0.708125, 0.704375, 0.698125, 0.7025  ,\n",
              "        0.700625, 0.7     , 0.704375, 0.708125, 0.704375, 0.698125,\n",
              "        0.7025  , 0.700625, 0.7     , 0.704375, 0.708125, 0.704375,\n",
              "        0.698125, 0.7025  , 0.700625, 0.7     , 0.704375, 0.708125,\n",
              "        0.704375, 0.698125, 0.7025  , 0.700625, 0.7     , 0.704375,\n",
              "        0.708125, 0.704375, 0.698125, 0.7025  , 0.700625, 0.7     ,\n",
              "        0.704375, 0.708125, 0.704375, 0.698125, 0.7025  , 0.700625,\n",
              "        0.7     , 0.704375, 0.708125, 0.704375, 0.698125, 0.7025  ,\n",
              "        0.700625, 0.7     , 0.704375, 0.708125, 0.704375, 0.698125,\n",
              "        0.7025  , 0.700625, 0.7     , 0.704375, 0.708125, 0.704375]),\n",
              " 'split3_test_score': array([0.6225  , 0.625625, 0.62875 , 0.626875, 0.633125, 0.644375,\n",
              "        0.645625, 0.6225  , 0.625625, 0.62875 , 0.626875, 0.633125,\n",
              "        0.644375, 0.645625, 0.6225  , 0.625625, 0.62875 , 0.626875,\n",
              "        0.633125, 0.644375, 0.645625, 0.6225  , 0.625625, 0.62875 ,\n",
              "        0.626875, 0.633125, 0.644375, 0.645625, 0.6225  , 0.625625,\n",
              "        0.62875 , 0.626875, 0.633125, 0.644375, 0.645625, 0.6225  ,\n",
              "        0.625625, 0.62875 , 0.626875, 0.633125, 0.644375, 0.645625,\n",
              "        0.6225  , 0.625625, 0.62875 , 0.626875, 0.633125, 0.644375,\n",
              "        0.645625, 0.6225  , 0.625625, 0.62875 , 0.626875, 0.633125,\n",
              "        0.644375, 0.645625, 0.6225  , 0.625625, 0.62875 , 0.626875,\n",
              "        0.633125, 0.644375, 0.645625, 0.6225  , 0.625625, 0.62875 ,\n",
              "        0.626875, 0.633125, 0.644375, 0.645625, 0.6225  , 0.625625,\n",
              "        0.62875 , 0.626875, 0.633125, 0.644375, 0.645625, 0.6225  ,\n",
              "        0.625625, 0.62875 , 0.626875, 0.633125, 0.644375, 0.645625]),\n",
              " 'split4_test_score': array([0.64477799, 0.6441526 , 0.6441526 , 0.6435272 , 0.6441526 ,\n",
              "        0.6441526 , 0.64290181, 0.64477799, 0.6441526 , 0.6441526 ,\n",
              "        0.6435272 , 0.6441526 , 0.6441526 , 0.64290181, 0.64477799,\n",
              "        0.6441526 , 0.6441526 , 0.6435272 , 0.6441526 , 0.6441526 ,\n",
              "        0.64290181, 0.64477799, 0.6441526 , 0.6441526 , 0.6435272 ,\n",
              "        0.6441526 , 0.6441526 , 0.64290181, 0.64477799, 0.6441526 ,\n",
              "        0.6441526 , 0.6435272 , 0.6441526 , 0.6441526 , 0.64290181,\n",
              "        0.64477799, 0.6441526 , 0.6441526 , 0.6435272 , 0.6441526 ,\n",
              "        0.6441526 , 0.64290181, 0.64477799, 0.6441526 , 0.6441526 ,\n",
              "        0.6435272 , 0.6441526 , 0.6441526 , 0.64290181, 0.64477799,\n",
              "        0.6441526 , 0.6441526 , 0.6435272 , 0.6441526 , 0.6441526 ,\n",
              "        0.64290181, 0.64477799, 0.6441526 , 0.6441526 , 0.6435272 ,\n",
              "        0.6441526 , 0.6441526 , 0.64290181, 0.64477799, 0.6441526 ,\n",
              "        0.6441526 , 0.6435272 , 0.6441526 , 0.6441526 , 0.64290181,\n",
              "        0.64477799, 0.6441526 , 0.6441526 , 0.6435272 , 0.6441526 ,\n",
              "        0.6441526 , 0.64290181, 0.64477799, 0.6441526 , 0.6441526 ,\n",
              "        0.6435272 , 0.6441526 , 0.6441526 , 0.64290181]),\n",
              " 'std_fit_time': array([0.00193768, 0.02211716, 0.01938245, 0.01445755, 0.01668148,\n",
              "        0.01598991, 0.01159234, 0.0114619 , 0.01275894, 0.0320179 ,\n",
              "        0.01658563, 0.00867161, 0.01046405, 0.01893287, 0.00444998,\n",
              "        0.01775408, 0.00805968, 0.02093077, 0.01533059, 0.02111391,\n",
              "        0.01815989, 0.01066221, 0.03179644, 0.01148697, 0.0130967 ,\n",
              "        0.00873719, 0.01755452, 0.0178107 , 0.0142398 , 0.01488299,\n",
              "        0.01682185, 0.01572428, 0.02676905, 0.01548176, 0.01868763,\n",
              "        0.01863317, 0.02002916, 0.02264309, 0.01585094, 0.01794872,\n",
              "        0.01169517, 0.02138046, 0.01314104, 0.01802443, 0.01438929,\n",
              "        0.01292156, 0.02944628, 0.01435013, 0.01238062, 0.01713163,\n",
              "        0.01215485, 0.01652489, 0.02533945, 0.01388721, 0.01839513,\n",
              "        0.0170912 , 0.0072475 , 0.012605  , 0.01325636, 0.01482121,\n",
              "        0.01270018, 0.01748523, 0.01799218, 0.01600267, 0.01912387,\n",
              "        0.01159474, 0.01013917, 0.01586411, 0.01473743, 0.02400636,\n",
              "        0.01785575, 0.01163227, 0.01196677, 0.01720439, 0.01902285,\n",
              "        0.01546202, 0.01441274, 0.01677146, 0.01746163, 0.01683629,\n",
              "        0.02548617, 0.016725  , 0.00953586, 0.01839167]),\n",
              " 'std_score_time': array([1.61469372, 1.45293169, 1.38957138, 1.34872448, 1.2916434 ,\n",
              "        0.95805917, 1.04588087, 0.7548108 , 0.70756822, 0.75187569,\n",
              "        0.71840885, 0.51296239, 0.62525308, 0.59927834, 0.28088518,\n",
              "        0.11736845, 0.24973054, 0.2216823 , 0.10820828, 0.17593261,\n",
              "        0.12163664, 0.72788723, 0.70932206, 0.70663965, 0.73794195,\n",
              "        0.65476579, 0.67387957, 0.51513344, 0.31507142, 0.3750017 ,\n",
              "        0.24785898, 0.2573883 , 0.27108615, 0.3140743 , 0.24753448,\n",
              "        0.2178456 , 0.26372249, 0.26303473, 0.24371125, 0.19944041,\n",
              "        0.21654275, 0.23888937, 0.30220938, 0.25383482, 0.26437823,\n",
              "        0.20769333, 0.23589264, 0.23689399, 0.22596747, 0.2440565 ,\n",
              "        0.19496601, 0.24621463, 0.29331072, 0.2888798 , 0.25681877,\n",
              "        0.20499892, 0.252854  , 0.24714895, 0.22012838, 0.23781574,\n",
              "        0.22389936, 0.20111033, 0.17168207, 0.17823557, 0.24995136,\n",
              "        0.25939892, 0.30003559, 0.16668824, 0.32519459, 0.20474238,\n",
              "        0.23873696, 0.20233241, 0.19771954, 0.15395524, 0.14702348,\n",
              "        0.1834865 , 0.23891804, 0.21811792, 0.14476826, 0.16825975,\n",
              "        0.13842891, 0.16755777, 0.2272695 , 0.83583765]),\n",
              " 'std_test_score': array([0.02983641, 0.0301579 , 0.02986306, 0.02987806, 0.02828007,\n",
              "        0.02844119, 0.0266098 , 0.02983641, 0.0301579 , 0.02986306,\n",
              "        0.02987806, 0.02828007, 0.02844119, 0.0266098 , 0.02983641,\n",
              "        0.0301579 , 0.02986306, 0.02987806, 0.02828007, 0.02844119,\n",
              "        0.0266098 , 0.02983641, 0.0301579 , 0.02986306, 0.02987806,\n",
              "        0.02828007, 0.02844119, 0.0266098 , 0.02983641, 0.0301579 ,\n",
              "        0.02986306, 0.02987806, 0.02828007, 0.02844119, 0.0266098 ,\n",
              "        0.02983641, 0.0301579 , 0.02986306, 0.02987806, 0.02828007,\n",
              "        0.02844119, 0.0266098 , 0.02983641, 0.0301579 , 0.02986306,\n",
              "        0.02987806, 0.02828007, 0.02844119, 0.0266098 , 0.02983641,\n",
              "        0.0301579 , 0.02986306, 0.02987806, 0.02828007, 0.02844119,\n",
              "        0.0266098 , 0.02983641, 0.0301579 , 0.02986306, 0.02987806,\n",
              "        0.02828007, 0.02844119, 0.0266098 , 0.02983641, 0.0301579 ,\n",
              "        0.02986306, 0.02987806, 0.02828007, 0.02844119, 0.0266098 ,\n",
              "        0.02983641, 0.0301579 , 0.02986306, 0.02987806, 0.02828007,\n",
              "        0.02844119, 0.0266098 , 0.02983641, 0.0301579 , 0.02986306,\n",
              "        0.02987806, 0.02828007, 0.02844119, 0.0266098 ])}"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "olGWTdasg-5I",
        "outputId": "66b7924d-fd4b-462c-b5a8-aac6a89213c4"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "plt.scatter(gsearch1.cv_results_['mean_test_score'],gsearch1.cv_results_['param_n_neighbors'])\n",
        "#gsearch1.cv_results_['param_leaf_size'], gsearch1.cv_results_['mean_test_score']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7f71dd1d9e50>"
            ]
          },
          "metadata": {},
          "execution_count": 89
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-EAsVMtrNB7L",
        "outputId": "33bd7ba6-0c3f-4fda-87b0-1c1014b95c30"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "\n",
        "param_knn = {}\n",
        "param_knn['n_neighbors'] = 400\n",
        "param_knn['leaf_size'] = 50\n",
        "\n",
        "knn = KNeighborsClassifier(**param_knn)\n",
        "knn.fit(X_train,y_train)\n",
        "\n",
        "y_test_pred = knn.predict(X_test)\n",
        "y_train_pred= knn.predict(X_train)\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "print(f'Train score {accuracy_score(y_train_pred,y_train)}')\n",
        "print(f'Test score {accuracy_score(y_test_pred,y_test)}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train score 0.677584698087261\n",
            "Test score 0.6821862348178138\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zReW72Himxs7",
        "outputId": "2df365b6-f158-4ffa-c6e9-dc8bccfbc187"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "\n",
        "param_knn = {}\n",
        "param_knn['n_neighbors'] = 400\n",
        "param_knn['leaf_size'] = 25\n",
        "\n",
        "knn = KNeighborsClassifier(**param_knn)\n",
        "knn.fit(X_train,y_train)\n",
        "\n",
        "y_test_pred = knn.predict(X_test)\n",
        "y_train_pred= knn.predict(X_train)\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "print(f'Train score {accuracy_score(y_train_pred,y_train)}')\n",
        "print(f'Test score {accuracy_score(y_test_pred,y_test)}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train score 0.677584698087261\n",
            "Test score 0.6821862348178138\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jg8XD0pOnEiw",
        "outputId": "2e0c4d04-71d5-49c3-99ef-34b30b261046"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "\n",
        "param_knn = {}\n",
        "param_knn['n_neighbors'] = 400\n",
        "param_knn['leaf_size'] = 100\n",
        "\n",
        "knn = KNeighborsClassifier(**param_knn)\n",
        "knn.fit(X_train,y_train)\n",
        "\n",
        "y_test_pred = knn.predict(X_test)\n",
        "y_train_pred= knn.predict(X_train)\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "print(f'Train score {accuracy_score(y_train_pred,y_train)}')\n",
        "print(f'Test score {accuracy_score(y_test_pred,y_test)}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train score 0.677584698087261\n",
            "Test score 0.6821862348178138\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c8mk29RHnLXj",
        "outputId": "0c341877-6640-470d-b004-1f855e98f46c"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "\n",
        "param_knn = {}\n",
        "param_knn['n_neighbors'] = 200\n",
        "param_knn['leaf_size'] = 100\n",
        "\n",
        "knn = KNeighborsClassifier(**param_knn)\n",
        "knn.fit(X_train,y_train)\n",
        "\n",
        "y_test_pred = knn.predict(X_test)\n",
        "y_train_pred= knn.predict(X_train)\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "print(f'Train score {accuracy_score(y_train_pred,y_train)}')\n",
        "print(f'Test score {accuracy_score(y_test_pred,y_test)}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train score 0.6810851356419553\n",
            "Test score 0.6821862348178138\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C3lQeM53nPkK",
        "outputId": "796c8fa1-f5ea-42ff-e073-44241d7a6008"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "\n",
        "param_knn = {}\n",
        "param_knn['n_neighbors'] = 800\n",
        "param_knn['leaf_size'] = 100\n",
        "\n",
        "knn = KNeighborsClassifier(**param_knn)\n",
        "knn.fit(X_train,y_train)\n",
        "\n",
        "y_test_pred = knn.predict(X_test)\n",
        "y_train_pred= knn.predict(X_train)\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "print(f'Train score {accuracy_score(y_train_pred,y_train)}')\n",
        "print(f'Test score {accuracy_score(y_test_pred,y_test)}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train score 0.6740842605325665\n",
            "Test score 0.6761133603238867\n"
          ]
        }
      ]
    }
  ]
}